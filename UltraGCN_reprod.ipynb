{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5eNm0wP9h_e"
      },
      "source": [
        "# Experiment Design Exercise 2\n",
        "11824496 Hartmann, Fabian  \n",
        "01015083 Hepp, Sebastian  \n",
        "01457320 Mayr, Yifan  \n",
        "11810738 Moik, Matthias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIuiLR6A9h_g"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/e11824496/ExpDesign_WS22.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nIXEQPY9qdh",
        "outputId": "cadf0819-85c7-4ba6-bb66-be9f3fd05c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ExpDesign_WS22'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 129 (delta 40), reused 51 (delta 16), pack-reused 50\u001b[K\n",
            "Receiving objects: 100% (129/129), 47.81 MiB | 14.33 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuiXu1ka0pn1",
        "outputId": "ae604ca8-c67c-42b6-a8ba-c9852559e377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ExpDesign_WS22/UltraGCN\n"
          ]
        }
      ],
      "source": [
        "%cd ExpDesign_WS22/UltraGCN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0trlZd1U9h_k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def print_eval(recall_reprod, ndcg_reprod, recall_paper, ndcg_paper, n_epochs_paper, n_epochs_reprod):\n",
        "    recall_reprod_off_by = (recall_reprod - recall_paper) / recall_paper\n",
        "    ndcg_reprod_off_by = (ndcg_reprod - ndcg_paper) / ndcg_paper\n",
        "    diff_epochs = n_epochs_paper - n_epochs_reprod\n",
        "\n",
        "    print(f\"reproduced recall off by {round(recall_reprod_off_by * 100, 2)}%\")\n",
        "    print(f\"reproduced NDCG off by {round(ndcg_reprod_off_by * 100, 2)}%\")\n",
        "    print()\n",
        "    print(f\"difference in epochs needed when reproducing: {diff_epochs} epochs or {round((diff_epochs) / n_epochs_reprod * 100, 2)}%\")\n",
        "\n",
        "\n",
        "#92000 items, 52000 users\n",
        "def sample_amazon_set(user_cutoff, item_cutoff, seed = 42):\n",
        "    train_file = open(\"data/amazon/train.txt\",\"r+\")\n",
        "    train_data = train_file.readlines()\n",
        "    test_file = open(\"data/amazon/test.txt\",\"r+\")\n",
        "    test_data = test_file.readlines()\n",
        "    item_list = open(\"data/amazon/item_list.txt\",\"r+\")\n",
        "    n_items = len(item_list.readlines())-1\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    sampled_items = {k: i for i, k in enumerate(np.random.choice(np.arange(n_items), item_cutoff, replace = False))}\n",
        "\n",
        "    train_file_out = open(\"data/amazon_sampled/train.txt\", \"w\")\n",
        "    test_file_out = open(\"data/amazon_sampled/test.txt\", \"w\")\n",
        "\n",
        "\n",
        "    current_line = 0\n",
        "    current_user_id = 0\n",
        "    while current_user_id < user_cutoff and current_line < len(train_data):\n",
        "        line = train_data[current_line]\n",
        "        current_user_items_train = [int(x) for x in line.split()[1:]]\n",
        "        current_user_items_train_filterd = [sampled_items[x] for x in current_user_items_train if x in sampled_items]\n",
        "        \n",
        "        line = test_data[current_line]\n",
        "        current_user_items_test = [int(x) for x in line.split()[1:]]\n",
        "        current_user_items_test_filterd = [sampled_items[x] for x in current_user_items_test if x in sampled_items]\n",
        "\n",
        "        if len(current_user_items_train_filterd) < 5 or len(current_user_items_test_filterd) < 2: \n",
        "            current_line += 1\n",
        "            continue\n",
        "        else:\n",
        "            train_file_out.write(\" \".join(map(str,[current_user_id] + current_user_items_train_filterd)) + '\\n')\n",
        "            test_file_out.write(\" \".join(map(str,[current_user_id] + current_user_items_test_filterd)) + '\\n')\n",
        "            current_user_id += 1\n",
        "            current_line += 1\n",
        "\n",
        "    print(f'Number of users: {current_user_id}')\n",
        "  \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dggt1PHZ9h_n"
      },
      "source": [
        "## Reproducing ML-1M results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import main_custom_parameters as main"
      ],
      "metadata": {
        "id": "nKkx5KVB57v-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxRKrxBq0ty1",
        "outputId": "3ebcf73e-5dbc-4ff5-ff12-b65876efe5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing \\Omega for the item-item graph... \n",
            "i-i constraint matrix 0 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./ml-1m_ii_neighbor_mat_10 ok\n",
            "store object in path = ./ml-1m_ii_constraint_mat_10 ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'train_file_path': './data/ml-1m/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0.0001, 'lambda': 0.001, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/ml-1m/test.txt', 'device': device(type='cuda', index=0), 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time for epoch 0 is: train time = 00: 00: 10, test time = 00: 00: 01\n",
            "Loss = 21.25471, F1-score: 0.091753 \t Precision: 0.07649\t Recall: 0.11464\tNDCG: 0.11558\n",
            "The time for epoch 5 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.79668, F1-score: 0.090951 \t Precision: 0.07589\t Recall: 0.11347\tNDCG: 0.11486\n",
            "The time for epoch 10 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.97693, F1-score: 0.091365 \t Precision: 0.07588\t Recall: 0.11479\tNDCG: 0.11401\n",
            "The time for epoch 15 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.40684, F1-score: 0.128047 \t Precision: 0.10673\t Recall: 0.16002\tNDCG: 0.16888\n",
            "The time for epoch 20 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.97007, F1-score: 0.159057 \t Precision: 0.12943\t Recall: 0.20627\tNDCG: 0.20744\n",
            "The time for epoch 25 is: train time = 00: 00: 11, test time = 00: 00: 00\n",
            "Loss = 17.08687, F1-score: 0.172493 \t Precision: 0.13814\t Recall: 0.22958\tNDCG: 0.22540\n",
            "The time for epoch 30 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.34563, F1-score: 0.180385 \t Precision: 0.14347\t Recall: 0.24286\tNDCG: 0.23594\n",
            "The time for epoch 35 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.72394, F1-score: 0.186973 \t Precision: 0.14772\t Recall: 0.25464\tNDCG: 0.24451\n",
            "The time for epoch 40 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.27929, F1-score: 0.191247 \t Precision: 0.15079\t Recall: 0.26138\tNDCG: 0.25168\n",
            "The time for epoch 45 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.55980, F1-score: 0.194262 \t Precision: 0.15280\t Recall: 0.26661\tNDCG: 0.25440\n",
            "The time for epoch 50 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.43217, F1-score: 0.196008 \t Precision: 0.15385\t Recall: 0.26998\tNDCG: 0.25811\n",
            "The time for epoch 51 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.81979, F1-score: 0.197347 \t Precision: 0.15482\t Recall: 0.27207\tNDCG: 0.25856\n",
            "The time for epoch 52 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.37509, F1-score: 0.196578 \t Precision: 0.15444\t Recall: 0.27033\tNDCG: 0.25871\n",
            "The time for epoch 53 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.69800, F1-score: 0.196167 \t Precision: 0.15409\t Recall: 0.26984\tNDCG: 0.25794\n",
            "The time for epoch 54 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.77402, F1-score: 0.197051 \t Precision: 0.15468\t Recall: 0.27139\tNDCG: 0.25906\n",
            "The time for epoch 55 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.67754, F1-score: 0.197495 \t Precision: 0.15474\t Recall: 0.27289\tNDCG: 0.25975\n",
            "The time for epoch 56 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.67567, F1-score: 0.197819 \t Precision: 0.15526\t Recall: 0.27253\tNDCG: 0.26033\n",
            "The time for epoch 57 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.36934, F1-score: 0.197702 \t Precision: 0.15488\t Recall: 0.27324\tNDCG: 0.26021\n",
            "The time for epoch 58 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.06416, F1-score: 0.198414 \t Precision: 0.15566\t Recall: 0.27354\tNDCG: 0.26092\n",
            "The time for epoch 59 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.13772, F1-score: 0.198237 \t Precision: 0.15522\t Recall: 0.27423\tNDCG: 0.25996\n",
            "The time for epoch 60 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.94560, F1-score: 0.198965 \t Precision: 0.15575\t Recall: 0.27538\tNDCG: 0.26106\n",
            "The time for epoch 61 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.50524, F1-score: 0.198735 \t Precision: 0.15541\t Recall: 0.27557\tNDCG: 0.26186\n",
            "The time for epoch 62 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.06316, F1-score: 0.199404 \t Precision: 0.15621\t Recall: 0.27561\tNDCG: 0.26232\n",
            "The time for epoch 63 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.88540, F1-score: 0.199129 \t Precision: 0.15599\t Recall: 0.27526\tNDCG: 0.26228\n",
            "The time for epoch 64 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.23295, F1-score: 0.199575 \t Precision: 0.15626\t Recall: 0.27611\tNDCG: 0.26206\n",
            "The time for epoch 65 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.02769, F1-score: 0.199647 \t Precision: 0.15629\t Recall: 0.27628\tNDCG: 0.26305\n",
            "The time for epoch 66 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.58616, F1-score: 0.199265 \t Precision: 0.15629\t Recall: 0.27483\tNDCG: 0.26293\n",
            "The time for epoch 67 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.14417, F1-score: 0.199368 \t Precision: 0.15591\t Recall: 0.27641\tNDCG: 0.26248\n",
            "The time for epoch 68 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.25912, F1-score: 0.199467 \t Precision: 0.15613\t Recall: 0.27611\tNDCG: 0.26223\n",
            "The time for epoch 69 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.24796, F1-score: 0.200065 \t Precision: 0.15664\t Recall: 0.27679\tNDCG: 0.26382\n",
            "The time for epoch 70 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.78832, F1-score: 0.199311 \t Precision: 0.15604\t Recall: 0.27580\tNDCG: 0.26279\n",
            "The time for epoch 71 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.98040, F1-score: 0.200101 \t Precision: 0.15660\t Recall: 0.27706\tNDCG: 0.26336\n",
            "The time for epoch 72 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.65329, F1-score: 0.199492 \t Precision: 0.15600\t Recall: 0.27660\tNDCG: 0.26317\n",
            "The time for epoch 73 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.16081, F1-score: 0.199759 \t Precision: 0.15625\t Recall: 0.27684\tNDCG: 0.26301\n",
            "The time for epoch 74 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.94111, F1-score: 0.199762 \t Precision: 0.15639\t Recall: 0.27641\tNDCG: 0.26264\n",
            "The time for epoch 75 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.68859, F1-score: 0.200150 \t Precision: 0.15653\t Recall: 0.27748\tNDCG: 0.26304\n",
            "The time for epoch 76 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.46973, F1-score: 0.199918 \t Precision: 0.15649\t Recall: 0.27670\tNDCG: 0.26308\n",
            "The time for epoch 77 is: train time = 00: 00: 12, test time = 00: 00: 00\n",
            "Loss = 16.94369, F1-score: 0.200364 \t Precision: 0.15679\t Recall: 0.27747\tNDCG: 0.26304\n",
            "The time for epoch 78 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.40700, F1-score: 0.199470 \t Precision: 0.15591\t Recall: 0.27680\tNDCG: 0.26242\n",
            "The time for epoch 79 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.60538, F1-score: 0.200393 \t Precision: 0.15678\t Recall: 0.27761\tNDCG: 0.26288\n",
            "The time for epoch 80 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.69643, F1-score: 0.199642 \t Precision: 0.15634\t Recall: 0.27613\tNDCG: 0.26389\n",
            "The time for epoch 81 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.68961, F1-score: 0.199727 \t Precision: 0.15610\t Recall: 0.27719\tNDCG: 0.26349\n",
            "The time for epoch 82 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.28046, F1-score: 0.198641 \t Precision: 0.15536\t Recall: 0.27534\tNDCG: 0.26146\n",
            "The time for epoch 83 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.03094, F1-score: 0.199187 \t Precision: 0.15579\t Recall: 0.27611\tNDCG: 0.26229\n",
            "The time for epoch 84 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.37195, F1-score: 0.200006 \t Precision: 0.15654\t Recall: 0.27688\tNDCG: 0.26373\n",
            "The time for epoch 85 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.90942, F1-score: 0.198444 \t Precision: 0.15521\t Recall: 0.27508\tNDCG: 0.26164\n",
            "The time for epoch 86 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.95640, F1-score: 0.199616 \t Precision: 0.15615\t Recall: 0.27661\tNDCG: 0.26275\n",
            "The time for epoch 87 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.60215, F1-score: 0.199807 \t Precision: 0.15658\t Recall: 0.27599\tNDCG: 0.26323\n",
            "The time for epoch 88 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.78141, F1-score: 0.199765 \t Precision: 0.15614\t Recall: 0.27721\tNDCG: 0.26361\n",
            "The time for epoch 89 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.03058, F1-score: 0.198844 \t Precision: 0.15557\t Recall: 0.27546\tNDCG: 0.26164\n",
            "The time for epoch 90 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.23529, F1-score: 0.199239 \t Precision: 0.15595\t Recall: 0.27578\tNDCG: 0.26190\n",
            "The time for epoch 91 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.69723, F1-score: 0.198952 \t Precision: 0.15570\t Recall: 0.27546\tNDCG: 0.26202\n",
            "The time for epoch 92 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.96794, F1-score: 0.199064 \t Precision: 0.15573\t Recall: 0.27581\tNDCG: 0.26239\n",
            "The time for epoch 93 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.44030, F1-score: 0.199257 \t Precision: 0.15600\t Recall: 0.27570\tNDCG: 0.26226\n",
            "The time for epoch 94 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.78732, F1-score: 0.198353 \t Precision: 0.15541\t Recall: 0.27410\tNDCG: 0.26053\n",
            "The time for epoch 95 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.78758, F1-score: 0.198516 \t Precision: 0.15523\t Recall: 0.27527\tNDCG: 0.26160\n",
            "The time for epoch 96 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.81708, F1-score: 0.199653 \t Precision: 0.15627\t Recall: 0.27639\tNDCG: 0.26379\n",
            "The time for epoch 97 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.68157, F1-score: 0.197833 \t Precision: 0.15485\t Recall: 0.27385\tNDCG: 0.26068\n",
            "The time for epoch 98 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.88536, F1-score: 0.198718 \t Precision: 0.15565\t Recall: 0.27473\tNDCG: 0.26173\n",
            "The time for epoch 99 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.87773, F1-score: 0.198682 \t Precision: 0.15558\t Recall: 0.27482\tNDCG: 0.26221\n",
            "The time for epoch 100 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.91182, F1-score: 0.199148 \t Precision: 0.15608\t Recall: 0.27505\tNDCG: 0.26238\n",
            "The time for epoch 101 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.44058, F1-score: 0.198784 \t Precision: 0.15562\t Recall: 0.27508\tNDCG: 0.26195\n",
            "The time for epoch 102 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.24795, F1-score: 0.199414 \t Precision: 0.15613\t Recall: 0.27591\tNDCG: 0.26207\n",
            "The time for epoch 103 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.01192, F1-score: 0.198766 \t Precision: 0.15556\t Recall: 0.27519\tNDCG: 0.26241\n",
            "The time for epoch 104 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.35666, F1-score: 0.198120 \t Precision: 0.15525\t Recall: 0.27370\tNDCG: 0.26112\n",
            "The time for epoch 105 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.27781, F1-score: 0.198386 \t Precision: 0.15518\t Recall: 0.27493\tNDCG: 0.26142\n",
            "The time for epoch 106 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.31026, F1-score: 0.198583 \t Precision: 0.15548\t Recall: 0.27475\tNDCG: 0.26233\n",
            "The time for epoch 107 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.24208, F1-score: 0.198639 \t Precision: 0.15558\t Recall: 0.27466\tNDCG: 0.26212\n",
            "The time for epoch 108 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.74360, F1-score: 0.198363 \t Precision: 0.15524\t Recall: 0.27466\tNDCG: 0.26187\n",
            "The time for epoch 109 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.54774, F1-score: 0.199232 \t Precision: 0.15569\t Recall: 0.27659\tNDCG: 0.26256\n",
            "The time for epoch 110 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.35912, F1-score: 0.198366 \t Precision: 0.15541\t Recall: 0.27415\tNDCG: 0.26176\n",
            "The time for epoch 111 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.32475, F1-score: 0.198638 \t Precision: 0.15550\t Recall: 0.27488\tNDCG: 0.26092\n",
            "The time for epoch 112 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.50459, F1-score: 0.198546 \t Precision: 0.15551\t Recall: 0.27450\tNDCG: 0.26134\n",
            "The time for epoch 113 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.36375, F1-score: 0.198038 \t Precision: 0.15503\t Recall: 0.27407\tNDCG: 0.26025\n",
            "The time for epoch 114 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.81861, F1-score: 0.198853 \t Precision: 0.15556\t Recall: 0.27552\tNDCG: 0.26147\n",
            "The time for epoch 115 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.73046, F1-score: 0.198306 \t Precision: 0.15516\t Recall: 0.27470\tNDCG: 0.26158\n",
            "The time for epoch 116 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.92220, F1-score: 0.198581 \t Precision: 0.15548\t Recall: 0.27474\tNDCG: 0.26006\n",
            "The time for epoch 117 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.24695, F1-score: 0.198228 \t Precision: 0.15489\t Recall: 0.27524\tNDCG: 0.26012\n",
            "The time for epoch 118 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.33641, F1-score: 0.197812 \t Precision: 0.15486\t Recall: 0.27374\tNDCG: 0.26155\n",
            "The time for epoch 119 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.14535, F1-score: 0.197679 \t Precision: 0.15472\t Recall: 0.27365\tNDCG: 0.26028\n",
            "The time for epoch 120 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.05433, F1-score: 0.198116 \t Precision: 0.15511\t Recall: 0.27411\tNDCG: 0.25999\n",
            "The time for epoch 121 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.39380, F1-score: 0.197976 \t Precision: 0.15481\t Recall: 0.27453\tNDCG: 0.26089\n",
            "The time for epoch 122 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.08559, F1-score: 0.196936 \t Precision: 0.15437\t Recall: 0.27192\tNDCG: 0.25942\n",
            "The time for epoch 123 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.76728, F1-score: 0.198372 \t Precision: 0.15541\t Recall: 0.27418\tNDCG: 0.26120\n",
            "The time for epoch 124 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.31390, F1-score: 0.197951 \t Precision: 0.15499\t Recall: 0.27386\tNDCG: 0.26052\n",
            "The time for epoch 125 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.03609, F1-score: 0.197569 \t Precision: 0.15457\t Recall: 0.27369\tNDCG: 0.26087\n",
            "The time for epoch 126 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.65282, F1-score: 0.198503 \t Precision: 0.15547\t Recall: 0.27447\tNDCG: 0.26096\n",
            "The time for epoch 127 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.26072, F1-score: 0.198456 \t Precision: 0.15530\t Recall: 0.27484\tNDCG: 0.26224\n",
            "The time for epoch 128 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.95123, F1-score: 0.198327 \t Precision: 0.15526\t Recall: 0.27447\tNDCG: 0.26152\n",
            "The time for epoch 129 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.72049, F1-score: 0.198101 \t Precision: 0.15502\t Recall: 0.27433\tNDCG: 0.25996\n",
            "##########################################\n",
            "Early stop is triggered at 129 epochs.\n",
            "Results:\n",
            "best epoch = 79, best recall = 0.2776111303103336, best ndcg = 0.2628752288965452\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "main.run('ml-1m_config.ini')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_paper = 0.2787\n",
        "ndcg_paper = 0.2642\n",
        "epochs_paper = 136\n",
        "\n",
        "recall_reprod = 0.2776111303103336\n",
        "ndcg_reprod = 0.2628752288965452\n",
        "epochs_reprod = 129\n",
        "\n",
        "print_eval(recall_reprod, ndcg_reprod, recall_paper, ndcg_paper, epochs_paper, epochs_reprod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu0nl0dY6l1b",
        "outputId": "e27a7a0f-fce7-47e5-b183-c79e234e67a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reproduced recall off by -0.39%\n",
            "reproduced NDCG off by -0.5%\n",
            "\n",
            "difference in epochs needed when reproducing: 0 epochs or 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g87E0yAo9h_p"
      },
      "source": [
        "## Reproducing Amazon results (sampled dataset due to RAM constraints)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_amazon_set(17547, 30863) # 33% of users and items\n",
        "sample_amazon_set(21057, 36640) # 40% of users and items"
      ],
      "metadata": {
        "id": "O7thDTsK0g3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e248941c-a79c-4354-ab71-f793ab866ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 21057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main.run('amazon_sampled_config.ini')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0s41X5K9lAh",
        "outputId": "e8d52050-9a56-4160-a7d3-d0a98eb11410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing \\Omega for the item-item graph... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ExpDesign_WS22/UltraGCN/main_custom_parameters.py:95: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  beta_uD = (np.sqrt(users_D + 1) / users_D).reshape(-1, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i-i constraint matrix 0 ok\n",
            "i-i constraint matrix 15000 ok\n",
            "i-i constraint matrix 30000 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./amazon_sampled_ii_neighbor_mat_10 ok\n",
            "store object in path = ./amazon_sampled_ii_constraint_mat_10 ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 64, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_amazon_sampled.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.0001, 'dataset': 'amazon_sampled', 'train_file_path': './data/amazon_sampled/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 15, 'w1': 1e-08, 'w2': 1.0, 'w3': 1.0, 'w4': 1e-08, 'negative_num': 500, 'negative_weight': 500.0, 'gamma': 0.0001, 'lambda': 2.75, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/amazon_sampled/test.txt', 'device': device(type='cuda', index=0), 'user_num': 21057, 'item_num': 36640}\n",
            "Total training batches = 493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time for epoch 0 is: train time = 00: 00: 14, test time = 00: 00: 08\n",
            "Loss = 26009.67773, F1-score: 0.001783 \t Precision: 0.00113\t Recall: 0.00429\tNDCG: 0.00407\n",
            "The time for epoch 5 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1747.20483, F1-score: 0.004798 \t Precision: 0.00302\t Recall: 0.01169\tNDCG: 0.00795\n",
            "The time for epoch 10 is: train time = 00: 00: 12, test time = 00: 00: 05\n",
            "Loss = 1577.30396, F1-score: 0.004786 \t Precision: 0.00300\t Recall: 0.01177\tNDCG: 0.00788\n",
            "The time for epoch 15 is: train time = 00: 00: 12, test time = 00: 00: 05\n",
            "Loss = 1511.96423, F1-score: 0.004791 \t Precision: 0.00301\t Recall: 0.01180\tNDCG: 0.00807\n",
            "The time for epoch 20 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1501.38989, F1-score: 0.004253 \t Precision: 0.00268\t Recall: 0.01035\tNDCG: 0.00723\n",
            "The time for epoch 25 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1490.27222, F1-score: 0.005038 \t Precision: 0.00318\t Recall: 0.01217\tNDCG: 0.00796\n",
            "The time for epoch 30 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1396.21899, F1-score: 0.009431 \t Precision: 0.00600\t Recall: 0.02202\tNDCG: 0.01416\n",
            "The time for epoch 35 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1232.59644, F1-score: 0.014812 \t Precision: 0.00940\t Recall: 0.03487\tNDCG: 0.02276\n",
            "The time for epoch 40 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1100.63293, F1-score: 0.018493 \t Precision: 0.01167\t Recall: 0.04458\tNDCG: 0.02923\n",
            "The time for epoch 45 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1066.30872, F1-score: 0.020581 \t Precision: 0.01290\t Recall: 0.05082\tNDCG: 0.03284\n",
            "The time for epoch 50 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1007.19067, F1-score: 0.021655 \t Precision: 0.01354\t Recall: 0.05409\tNDCG: 0.03527\n",
            "The time for epoch 51 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 994.82715, F1-score: 0.021700 \t Precision: 0.01356\t Recall: 0.05428\tNDCG: 0.03555\n",
            "The time for epoch 52 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1026.78845, F1-score: 0.021807 \t Precision: 0.01363\t Recall: 0.05455\tNDCG: 0.03568\n",
            "The time for epoch 53 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 1005.13965, F1-score: 0.022001 \t Precision: 0.01373\t Recall: 0.05530\tNDCG: 0.03636\n",
            "The time for epoch 54 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 972.96777, F1-score: 0.022294 \t Precision: 0.01391\t Recall: 0.05617\tNDCG: 0.03652\n",
            "The time for epoch 55 is: train time = 00: 00: 12, test time = 00: 00: 05\n",
            "Loss = 999.31665, F1-score: 0.022130 \t Precision: 0.01381\t Recall: 0.05574\tNDCG: 0.03639\n",
            "The time for epoch 56 is: train time = 00: 00: 12, test time = 00: 00: 05\n",
            "Loss = 964.74780, F1-score: 0.022350 \t Precision: 0.01394\t Recall: 0.05630\tNDCG: 0.03686\n",
            "The time for epoch 57 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 960.92694, F1-score: 0.022349 \t Precision: 0.01392\t Recall: 0.05670\tNDCG: 0.03696\n",
            "The time for epoch 58 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 965.32233, F1-score: 0.022306 \t Precision: 0.01389\t Recall: 0.05654\tNDCG: 0.03683\n",
            "The time for epoch 59 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 959.68982, F1-score: 0.022341 \t Precision: 0.01390\t Recall: 0.05684\tNDCG: 0.03704\n",
            "The time for epoch 60 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 954.47998, F1-score: 0.022286 \t Precision: 0.01387\t Recall: 0.05665\tNDCG: 0.03708\n",
            "The time for epoch 61 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 911.32019, F1-score: 0.022426 \t Precision: 0.01396\t Recall: 0.05695\tNDCG: 0.03725\n",
            "The time for epoch 62 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 932.48322, F1-score: 0.022478 \t Precision: 0.01399\t Recall: 0.05710\tNDCG: 0.03726\n",
            "The time for epoch 63 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 917.02917, F1-score: 0.022323 \t Precision: 0.01388\t Recall: 0.05693\tNDCG: 0.03719\n",
            "The time for epoch 64 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 920.62787, F1-score: 0.022364 \t Precision: 0.01391\t Recall: 0.05702\tNDCG: 0.03719\n",
            "The time for epoch 65 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 935.51630, F1-score: 0.022152 \t Precision: 0.01375\t Recall: 0.05691\tNDCG: 0.03690\n",
            "The time for epoch 66 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 913.33527, F1-score: 0.022342 \t Precision: 0.01387\t Recall: 0.05733\tNDCG: 0.03716\n",
            "The time for epoch 67 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 907.60315, F1-score: 0.022362 \t Precision: 0.01391\t Recall: 0.05699\tNDCG: 0.03718\n",
            "The time for epoch 68 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 903.91357, F1-score: 0.022337 \t Precision: 0.01388\t Recall: 0.05719\tNDCG: 0.03712\n",
            "The time for epoch 69 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 918.36304, F1-score: 0.022267 \t Precision: 0.01384\t Recall: 0.05696\tNDCG: 0.03723\n",
            "The time for epoch 70 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 903.40930, F1-score: 0.022392 \t Precision: 0.01391\t Recall: 0.05742\tNDCG: 0.03729\n",
            "The time for epoch 71 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 912.34216, F1-score: 0.022227 \t Precision: 0.01381\t Recall: 0.05688\tNDCG: 0.03718\n",
            "The time for epoch 72 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 911.82697, F1-score: 0.022260 \t Precision: 0.01385\t Recall: 0.05675\tNDCG: 0.03713\n",
            "The time for epoch 73 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 899.79834, F1-score: 0.022105 \t Precision: 0.01374\t Recall: 0.05644\tNDCG: 0.03696\n",
            "The time for epoch 74 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 884.32214, F1-score: 0.022178 \t Precision: 0.01379\t Recall: 0.05656\tNDCG: 0.03726\n",
            "The time for epoch 75 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 911.19678, F1-score: 0.021910 \t Precision: 0.01362\t Recall: 0.05602\tNDCG: 0.03702\n",
            "The time for epoch 76 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 908.07367, F1-score: 0.022021 \t Precision: 0.01368\t Recall: 0.05643\tNDCG: 0.03690\n",
            "The time for epoch 77 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 886.17413, F1-score: 0.022095 \t Precision: 0.01374\t Recall: 0.05635\tNDCG: 0.03701\n",
            "The time for epoch 78 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 882.87872, F1-score: 0.021966 \t Precision: 0.01365\t Recall: 0.05623\tNDCG: 0.03706\n",
            "The time for epoch 79 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 874.79907, F1-score: 0.021850 \t Precision: 0.01359\t Recall: 0.05564\tNDCG: 0.03672\n",
            "The time for epoch 80 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 857.81458, F1-score: 0.021957 \t Precision: 0.01367\t Recall: 0.05583\tNDCG: 0.03678\n",
            "The time for epoch 81 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 859.84692, F1-score: 0.021913 \t Precision: 0.01362\t Recall: 0.05610\tNDCG: 0.03685\n",
            "The time for epoch 82 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 858.06146, F1-score: 0.021761 \t Precision: 0.01353\t Recall: 0.05548\tNDCG: 0.03662\n",
            "The time for epoch 83 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 863.72284, F1-score: 0.021779 \t Precision: 0.01354\t Recall: 0.05563\tNDCG: 0.03657\n",
            "The time for epoch 84 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 877.54102, F1-score: 0.021848 \t Precision: 0.01358\t Recall: 0.05589\tNDCG: 0.03668\n",
            "The time for epoch 85 is: train time = 00: 00: 11, test time = 00: 00: 05\n",
            "Loss = 871.27148, F1-score: 0.022015 \t Precision: 0.01369\t Recall: 0.05611\tNDCG: 0.03686\n",
            "##########################################\n",
            "Early stop is triggered at 85 epochs.\n",
            "Results:\n",
            "best epoch = 70, best recall = 0.057421455844465494, best ndcg = 0.03728846210162489\n",
            "The best model is saved at ./ultragcn_amazon_sampled.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927e7a01-ea29-4f66-c90f-af0a6c0f299e",
        "id": "GoKjA1SS9h_t"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reproduced recall off by -15.68%\n",
            "reproduced NDCG off by -32.93%\n",
            "\n",
            "difference in epochs needed when reproducing: 1 epochs or 1.18%\n"
          ]
        }
      ],
      "source": [
        "recall_paper = 0.0681\n",
        "ndcg_paper = 0.0556\n",
        "epochs_paper = 86\n",
        "\n",
        "recall_reprod = 0.057421455844465494\n",
        "ndcg_reprod = 0.03728846210162489\n",
        "epochs_reprod = 85\n",
        "\n",
        "print_eval(recall_reprod, ndcg_reprod, recall_paper, ndcg_paper, epochs_paper, epochs_reprod)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1XSpKHJNEe4"
      },
      "source": [
        "## Ablation study\n",
        "disable different parameters by overwriting:\n",
        "1. lambda = 0, gamma = 0\n",
        "1. lambda = 0\n",
        "1. gamma = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G82RyTggNXyn",
        "outputId": "8863b963-662e-4ec7-ee89-dc4a721c1b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "load path = ./amazon_sampled_ii_constraint_mat_10 object\n",
            "load path = ./amazon_sampled_ii_neighbor_mat_10 object\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 64, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_amazon_sampled.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.0001, 'dataset': 'amazon_sampled', 'train_file_path': './data/amazon_sampled/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 15, 'w1': 1e-08, 'w2': 1.0, 'w3': 1.0, 'w4': 1e-08, 'negative_num': 500, 'negative_weight': 500.0, 'gamma': 0.0, 'lambda': 0.0, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/amazon_sampled/test.txt', 'device': device(type='cuda', index=0), 'user_num': 21057, 'item_num': 36640}\n",
            "Total training batches = 493\n",
            "##########################################\n",
            "Early stop is triggered at 80 epochs.\n",
            "Results:\n",
            "best epoch = 65, best recall = 0.04918000384021738, best ndcg = 0.030738173917234976\n",
            "The best model is saved at ./ultragcn_amazon_sampled.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'gamma': 0, \n",
        "    'lambda': 0\n",
        "}\n",
        "main.run('amazon_sampled_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS-9lGmzPcEZ",
        "outputId": "37fbd36d-f106-4593-8da0-58dca448282a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "load path = ./amazon_sampled_ii_constraint_mat_10 object\n",
            "load path = ./amazon_sampled_ii_neighbor_mat_10 object\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 64, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_amazon_sampled.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.0001, 'dataset': 'amazon_sampled', 'train_file_path': './data/amazon_sampled/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 15, 'w1': 1e-08, 'w2': 1.0, 'w3': 1.0, 'w4': 1e-08, 'negative_num': 500, 'negative_weight': 500.0, 'gamma': 0.0001, 'lambda': 0.0, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/amazon_sampled/test.txt', 'device': device(type='cuda', index=0), 'user_num': 21057, 'item_num': 36640}\n",
            "Total training batches = 493\n",
            "##########################################\n",
            "Early stop is triggered at 89 epochs.\n",
            "Results:\n",
            "best epoch = 74, best recall = 0.050109096677435815, best ndcg = 0.031403093994895125\n",
            "The best model is saved at ./ultragcn_amazon_sampled.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'lambda': 0\n",
        "}\n",
        "main.run('amazon_sampled_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrG68foiPfUo",
        "outputId": "eaa52df6-d378-4896-8a5f-999b1539f5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "load path = ./amazon_sampled_ii_constraint_mat_10 object\n",
            "load path = ./amazon_sampled_ii_neighbor_mat_10 object\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 64, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_amazon_sampled.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.0001, 'dataset': 'amazon_sampled', 'train_file_path': './data/amazon_sampled/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 15, 'w1': 1e-08, 'w2': 1.0, 'w3': 1.0, 'w4': 1e-08, 'negative_num': 500, 'negative_weight': 500.0, 'gamma': 0.0, 'lambda': 2.75, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/amazon_sampled/test.txt', 'device': device(type='cuda', index=0), 'user_num': 21057, 'item_num': 36640}\n",
            "Total training batches = 493\n",
            "##########################################\n",
            "Early stop is triggered at 75 epochs.\n",
            "Results:\n",
            "best epoch = 60, best recall = 0.05677387126798456, best ndcg = 0.03702149429681787\n",
            "The best model is saved at ./ultragcn_amazon_sampled.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'gamma': 0 \n",
        "}\n",
        "main.run('amazon_sampled_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "AQsRg2DLUFNN",
        "outputId": "ec405828-e2a2-4b47-86ee-a83ae15b31b3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 4\n",
        "model_names = ['UltraGCN\\n(\\u03BB=0,\\u03B3=0)', 'UltraGCN\\n(\\u03B3=0)', 'UltraGCN\\n(\\u03BB=0)', 'UltraGCN']\n",
        "recall_results = [0.04918000384021738, 0.050109096677435815, 0.050109096677435815, recall_reprod]\n",
        "ndcg_results = [0.030738173917234976, 0.031403093994895125, 0.031403093994895125, ndcg_reprod]\n",
        "\n",
        "plt_, ax = plt.subplots(1, 2, figsize=(12,6))\n",
        "ax[0].bar(range(n), recall_results, width=0.9, tick_label=model_names)\n",
        "ax[0].set_xticks(range(n))\n",
        "ax[0].set_yticks(np.arange(0.02, 0.08, 0.01))\n",
        "ax[0].set_xlabel('model')\n",
        "ax[0].set_ylabel('Recall@20')\n",
        "\n",
        "ax[1].bar(range(n), ndcg_results, width=0.9, color='orange', tick_label=model_names)\n",
        "ax[1].set_xticks(range(n))\n",
        "ax[1].set_yticks(np.arange(0.02, 0.07, 0.01))\n",
        "ax[1].set_xlabel('model')\n",
        "ax[1].set_ylabel('NDCG@20')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwnGr_65MiRx"
      },
      "source": [
        "## Parameter Influence\n",
        "\n",
        "Appying different parameter settings. \n",
        "\n",
        "for K = [5, 10, 20, 50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z34o-vMTMzLr",
        "outputId": "31c575f2-c116-4ebc-a0db-ccf865533471"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load path = ./amazon_sampled_ii_constraint_mat_5 object\n",
            "load path = ./amazon_sampled_ii_neighbor_mat_5 object\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 64, 'ii_neighbor_num': 5, 'model_save_path': './ultragcn_amazon_sampled.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.0001, 'dataset': 'amazon_sampled', 'train_file_path': './data/amazon_sampled/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 15, 'w1': 1e-08, 'w2': 1.0, 'w3': 1.0, 'w4': 1e-08, 'negative_num': 500, 'negative_weight': 500.0, 'gamma': 0.0001, 'lambda': 2.75, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/amazon_sampled/test.txt', 'device': device(type='cuda', index=0), 'user_num': 21057, 'item_num': 36640}\n",
            "Total training batches = 493\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################\n",
            "Early stop is triggered at 79 epochs.\n",
            "Results:\n",
            "best epoch = 64, best recall = 0.05807551680906002, best ndcg = 0.03806443018640664\n",
            "The best model is saved at ./ultragcn_amazon_sampled.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'ii_neighbor_num': 5 \n",
        "}\n",
        "main.run('amazon_sampled_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_YkC6G4M91d",
        "outputId": "9311a9dd-f8e3-46e5-bd79-20e61212f379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing \\Omega for the item-item graph... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ExpDesign_WS22/UltraGCN/main_custom_parameters.py:95: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  beta_uD = (np.sqrt(users_D + 1) / users_D).reshape(-1, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i-i constraint matrix 0 ok\n",
            "i-i constraint matrix 15000 ok\n",
            "i-i constraint matrix 30000 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./amazon_sampled_ii_neighbor_mat_10 ok\n",
            "store object in path = ./amazon_sampled_ii_constraint_mat_10 ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 64, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_amazon_sampled.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.0001, 'dataset': 'amazon_sampled', 'train_file_path': './data/amazon_sampled/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 15, 'w1': 1e-08, 'w2': 1.0, 'w3': 1.0, 'w4': 1e-08, 'negative_num': 500, 'negative_weight': 500.0, 'gamma': 0.0001, 'lambda': 2.75, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/amazon_sampled/test.txt', 'device': device(type='cuda', index=0), 'user_num': 21057, 'item_num': 36640}\n",
            "Total training batches = 493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################\n",
            "Early stop is triggered at 74 epochs.\n",
            "Results:\n",
            "best epoch = 59, best recall = 0.057174523579523136, best ndcg = 0.03700182771757004\n",
            "The best model is saved at ./ultragcn_amazon_sampled.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'ii_neighbor_num': 10 \n",
        "}\n",
        "main.run('amazon_sampled_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psqs6YpQNF-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30fa3a0e-ccd8-4994-9c20-e3c7d21d6336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load path = ./amazon_sampled_ii_constraint_mat_20 object\n",
            "load path = ./amazon_sampled_ii_neighbor_mat_20 object\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 64, 'ii_neighbor_num': 20, 'model_save_path': './ultragcn_amazon_sampled.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.0001, 'dataset': 'amazon_sampled', 'train_file_path': './data/amazon_sampled/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 15, 'w1': 1e-08, 'w2': 1.0, 'w3': 1.0, 'w4': 1e-08, 'negative_num': 500, 'negative_weight': 500.0, 'gamma': 0.0001, 'lambda': 2.75, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/amazon_sampled/test.txt', 'device': device(type='cuda', index=0), 'user_num': 21057, 'item_num': 36640}\n",
            "Total training batches = 493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################\n",
            "Early stop is triggered at 89 epochs.\n",
            "Results:\n",
            "best epoch = 74, best recall = 0.057013581068301185, best ndcg = 0.03711069489658892\n",
            "The best model is saved at ./ultragcn_amazon_sampled.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'ii_neighbor_num': 20 \n",
        "}\n",
        "main.run('amazon_sampled_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3NdwNgkSNH-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1a03be-c870-41f1-9c85-91b6794f9682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load path = ./amazon_sampled_ii_constraint_mat_50 object\n",
            "load path = ./amazon_sampled_ii_neighbor_mat_50 object\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 64, 'ii_neighbor_num': 50, 'model_save_path': './ultragcn_amazon_sampled.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.0001, 'dataset': 'amazon_sampled', 'train_file_path': './data/amazon_sampled/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 15, 'w1': 1e-08, 'w2': 1.0, 'w3': 1.0, 'w4': 1e-08, 'negative_num': 500, 'negative_weight': 500.0, 'gamma': 0.0001, 'lambda': 2.75, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/amazon_sampled/test.txt', 'device': device(type='cuda', index=0), 'user_num': 21057, 'item_num': 36640}\n",
            "Total training batches = 493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################\n",
            "Early stop is triggered at 81 epochs.\n",
            "Results:\n",
            "best epoch = 66, best recall = 0.055200401269675084, best ndcg = 0.036106530659083765\n",
            "The best model is saved at ./ultragcn_amazon_sampled.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'ii_neighbor_num': 50 \n",
        "}\n",
        "main.run('amazon_sampled_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "97VMi9kqNJIv",
        "outputId": "2b7039e1-2bf4-41e7-8d99-d9a4659f02cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "n = 4\n",
        "k= [5, 10, 20, 50]\n",
        "recall_results = [0.058, 0.057, 0.057, 0.055]\n",
        "ndcg_results = [0.038, 0.037, 0.037, 0.036]\n",
        "\n",
        "plt_, ax = plt.subplots(1, 1, figsize=(6,6))\n",
        "ax.plot(k, recall_results, marker='D')\n",
        "ax.set_ylim(min(recall_results + ndcg_results)*0.9, max(recall_results + ndcg_results)*1.1)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xticks(k)\n",
        "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
        "ax.minorticks_off()\n",
        "ax.set_xlabel('K')\n",
        "ax.set_ylabel('Recall@20')\n",
        "ax.plot(k, ndcg_results, color = 'orange', marker='D')\n",
        "ax.legend(['Recall', 'NDCG'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtOKp7F_kyP7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "3b7a84cbed68cee8b2d902c7fb67e432dacaa152add68a2527cb1d6154323226"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}