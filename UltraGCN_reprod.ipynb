{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment Design Exercise 2\n",
        "Hartmann, Fabian  \n",
        "01015083 Hepp, Sebastian  \n",
        "Mayr, Yifan  \n",
        "Moik, Matthias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuiXu1ka0pn1",
        "outputId": "c9235406-1936-424f-f4e9-9d53f17b2e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ExpDesign_WS22/UltraGCN\n"
          ]
        }
      ],
      "source": [
        "%cd UltraGCN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_eval(recall_reprod, ndcg_reprod, recall_paper, ndcg_paper, n_epochs_paper, n_epochs_reprod):\n",
        "    recall_reprod_off_by = (recall_reprod - recall_paper) / recall_paper\n",
        "    ndcg_reprod_off_by = (ndcg_reprod - ndcg_paper) / ndcg_paper\n",
        "    diff_epochs = n_epochs_paper - n_epochs_reprod\n",
        "\n",
        "    print(f\"reproduced recall off by {round(recall_reprod_off_by * 100, 2)}%\")\n",
        "    print(f\"reproduced NDCG off by {round(ndcg_reprod_off_by * 100, 2)}%\")\n",
        "    print()\n",
        "    print(f\"difference in epochs needed when reproducing: {diff_epochs} epochs or {round((diff_epochs) / n_epochs_reprod * 100, 2)}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reproducing ML-1M results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxRKrxBq0ty1",
        "outputId": "ba4f2b9c-46ab-407e-b409-777c030b1589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Computing \\Omega for the item-item graph... \n",
            "i-i constraint matrix 0 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./ml-1m_ii_neighbor_mat ok\n",
            "store object in path = ./ml-1m_ii_constraint_mat ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'gpu': '0', 'device': device(type='cuda', index=0), 'lr': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0.0001, 'lambda': 0.001, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The time for epoch 0 is: train time = 00: 00: 12, test time = 00: 00: 03\n",
            "Loss = 19.91279, F1-score: 0.091681 \t Precision: 0.07648\t Recall: 0.11443\tNDCG: 0.11596\n",
            "The time for epoch 5 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 18.20638, F1-score: 0.091183 \t Precision: 0.07611\t Recall: 0.11370\tNDCG: 0.11528\n",
            "The time for epoch 10 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.27180, F1-score: 0.091290 \t Precision: 0.07566\t Recall: 0.11505\tNDCG: 0.11492\n",
            "The time for epoch 15 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.36341, F1-score: 0.129567 \t Precision: 0.10807\t Recall: 0.16174\tNDCG: 0.17017\n",
            "The time for epoch 20 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.40980, F1-score: 0.157493 \t Precision: 0.12776\t Recall: 0.20527\tNDCG: 0.20656\n",
            "The time for epoch 25 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 15.94931, F1-score: 0.172548 \t Precision: 0.13822\t Recall: 0.22957\tNDCG: 0.22600\n",
            "The time for epoch 30 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.08956, F1-score: 0.180317 \t Precision: 0.14316\t Recall: 0.24353\tNDCG: 0.23581\n",
            "The time for epoch 35 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.71270, F1-score: 0.186643 \t Precision: 0.14766\t Recall: 0.25360\tNDCG: 0.24537\n",
            "The time for epoch 40 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.71788, F1-score: 0.190880 \t Precision: 0.15045\t Recall: 0.26103\tNDCG: 0.25027\n",
            "The time for epoch 45 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.25968, F1-score: 0.193948 \t Precision: 0.15245\t Recall: 0.26649\tNDCG: 0.25476\n",
            "The time for epoch 50 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.46021, F1-score: 0.195854 \t Precision: 0.15364\t Recall: 0.27004\tNDCG: 0.25733\n",
            "The time for epoch 51 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.63280, F1-score: 0.196292 \t Precision: 0.15430\t Recall: 0.26968\tNDCG: 0.25750\n",
            "The time for epoch 52 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.13210, F1-score: 0.195734 \t Precision: 0.15352\t Recall: 0.26997\tNDCG: 0.25851\n",
            "The time for epoch 53 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.51927, F1-score: 0.196934 \t Precision: 0.15442\t Recall: 0.27176\tNDCG: 0.25941\n",
            "The time for epoch 54 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.26227, F1-score: 0.197346 \t Precision: 0.15480\t Recall: 0.27214\tNDCG: 0.25925\n",
            "The time for epoch 55 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.91007, F1-score: 0.198102 \t Precision: 0.15536\t Recall: 0.27330\tNDCG: 0.25907\n",
            "The time for epoch 56 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.31599, F1-score: 0.198551 \t Precision: 0.15549\t Recall: 0.27460\tNDCG: 0.26147\n",
            "The time for epoch 57 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.99549, F1-score: 0.198045 \t Precision: 0.15520\t Recall: 0.27357\tNDCG: 0.26098\n",
            "The time for epoch 58 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.24116, F1-score: 0.198808 \t Precision: 0.15577\t Recall: 0.27470\tNDCG: 0.26144\n",
            "The time for epoch 59 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.90167, F1-score: 0.198243 \t Precision: 0.15531\t Recall: 0.27397\tNDCG: 0.26043\n",
            "The time for epoch 60 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.68484, F1-score: 0.197994 \t Precision: 0.15521\t Recall: 0.27335\tNDCG: 0.26006\n",
            "The time for epoch 61 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.42635, F1-score: 0.198508 \t Precision: 0.15538\t Recall: 0.27477\tNDCG: 0.26016\n",
            "The time for epoch 62 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 16.87586, F1-score: 0.198482 \t Precision: 0.15541\t Recall: 0.27460\tNDCG: 0.26152\n",
            "The time for epoch 63 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.30175, F1-score: 0.199576 \t Precision: 0.15631\t Recall: 0.27596\tNDCG: 0.26252\n",
            "The time for epoch 64 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.01346, F1-score: 0.199258 \t Precision: 0.15608\t Recall: 0.27547\tNDCG: 0.26162\n",
            "The time for epoch 65 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.24036, F1-score: 0.199909 \t Precision: 0.15650\t Recall: 0.27664\tNDCG: 0.26345\n",
            "The time for epoch 66 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.88608, F1-score: 0.200522 \t Precision: 0.15717\t Recall: 0.27691\tNDCG: 0.26330\n",
            "The time for epoch 67 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.64177, F1-score: 0.200345 \t Precision: 0.15706\t Recall: 0.27657\tNDCG: 0.26273\n",
            "The time for epoch 68 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.25554, F1-score: 0.199704 \t Precision: 0.15633\t Recall: 0.27640\tNDCG: 0.26260\n",
            "The time for epoch 69 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.89302, F1-score: 0.199344 \t Precision: 0.15595\t Recall: 0.27619\tNDCG: 0.26208\n",
            "The time for epoch 70 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.88643, F1-score: 0.199997 \t Precision: 0.15652\t Recall: 0.27692\tNDCG: 0.26258\n",
            "The time for epoch 71 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.33965, F1-score: 0.199309 \t Precision: 0.15593\t Recall: 0.27613\tNDCG: 0.26210\n",
            "The time for epoch 72 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.19024, F1-score: 0.200470 \t Precision: 0.15692\t Recall: 0.27746\tNDCG: 0.26330\n",
            "The time for epoch 73 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.43772, F1-score: 0.199825 \t Precision: 0.15653\t Recall: 0.27621\tNDCG: 0.26311\n",
            "The time for epoch 74 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.39361, F1-score: 0.199676 \t Precision: 0.15600\t Recall: 0.27731\tNDCG: 0.26268\n",
            "The time for epoch 75 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.08416, F1-score: 0.199940 \t Precision: 0.15627\t Recall: 0.27749\tNDCG: 0.26380\n",
            "The time for epoch 76 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.93247, F1-score: 0.198850 \t Precision: 0.15558\t Recall: 0.27546\tNDCG: 0.26227\n",
            "The time for epoch 77 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.32383, F1-score: 0.200194 \t Precision: 0.15663\t Recall: 0.27734\tNDCG: 0.26282\n",
            "The time for epoch 78 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.85132, F1-score: 0.199939 \t Precision: 0.15634\t Recall: 0.27727\tNDCG: 0.26308\n",
            "The time for epoch 79 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.23942, F1-score: 0.199794 \t Precision: 0.15599\t Recall: 0.27779\tNDCG: 0.26392\n",
            "The time for epoch 80 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.41440, F1-score: 0.199836 \t Precision: 0.15612\t Recall: 0.27756\tNDCG: 0.26276\n",
            "The time for epoch 81 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.57565, F1-score: 0.199386 \t Precision: 0.15604\t Recall: 0.27609\tNDCG: 0.26250\n",
            "The time for epoch 82 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.72587, F1-score: 0.199825 \t Precision: 0.15616\t Recall: 0.27739\tNDCG: 0.26301\n",
            "The time for epoch 83 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.07525, F1-score: 0.199140 \t Precision: 0.15565\t Recall: 0.27634\tNDCG: 0.26143\n",
            "The time for epoch 84 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.54578, F1-score: 0.200285 \t Precision: 0.15660\t Recall: 0.27777\tNDCG: 0.26334\n",
            "The time for epoch 85 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.89867, F1-score: 0.199284 \t Precision: 0.15587\t Recall: 0.27622\tNDCG: 0.26174\n",
            "The time for epoch 86 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.38805, F1-score: 0.200570 \t Precision: 0.15695\t Recall: 0.27777\tNDCG: 0.26360\n",
            "The time for epoch 87 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.88093, F1-score: 0.199005 \t Precision: 0.15566\t Recall: 0.27580\tNDCG: 0.26287\n",
            "The time for epoch 88 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.91226, F1-score: 0.199392 \t Precision: 0.15600\t Recall: 0.27622\tNDCG: 0.26114\n",
            "The time for epoch 89 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.18582, F1-score: 0.199435 \t Precision: 0.15601\t Recall: 0.27635\tNDCG: 0.26297\n",
            "The time for epoch 90 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.27471, F1-score: 0.199320 \t Precision: 0.15590\t Recall: 0.27625\tNDCG: 0.26281\n",
            "The time for epoch 91 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.58468, F1-score: 0.199261 \t Precision: 0.15560\t Recall: 0.27697\tNDCG: 0.26200\n",
            "The time for epoch 92 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.18991, F1-score: 0.199370 \t Precision: 0.15601\t Recall: 0.27610\tNDCG: 0.26218\n",
            "The time for epoch 93 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.61106, F1-score: 0.199120 \t Precision: 0.15573\t Recall: 0.27603\tNDCG: 0.26248\n",
            "The time for epoch 94 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.95034, F1-score: 0.199775 \t Precision: 0.15606\t Recall: 0.27751\tNDCG: 0.26338\n",
            "The time for epoch 95 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.89729, F1-score: 0.200048 \t Precision: 0.15634\t Recall: 0.27770\tNDCG: 0.26443\n",
            "The time for epoch 96 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.14818, F1-score: 0.199671 \t Precision: 0.15624\t Recall: 0.27656\tNDCG: 0.26281\n",
            "The time for epoch 97 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.68124, F1-score: 0.198959 \t Precision: 0.15550\t Recall: 0.27614\tNDCG: 0.26161\n",
            "The time for epoch 98 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.29868, F1-score: 0.199153 \t Precision: 0.15565\t Recall: 0.27639\tNDCG: 0.26193\n",
            "The time for epoch 99 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.21339, F1-score: 0.199464 \t Precision: 0.15585\t Recall: 0.27699\tNDCG: 0.26225\n",
            "The time for epoch 100 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.55200, F1-score: 0.199024 \t Precision: 0.15572\t Recall: 0.27569\tNDCG: 0.26196\n",
            "The time for epoch 101 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.78485, F1-score: 0.199040 \t Precision: 0.15576\t Recall: 0.27562\tNDCG: 0.26147\n",
            "The time for epoch 102 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.93698, F1-score: 0.198659 \t Precision: 0.15547\t Recall: 0.27507\tNDCG: 0.26108\n",
            "The time for epoch 103 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.26036, F1-score: 0.198038 \t Precision: 0.15497\t Recall: 0.27427\tNDCG: 0.26016\n",
            "The time for epoch 104 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.59708, F1-score: 0.198702 \t Precision: 0.15529\t Recall: 0.27581\tNDCG: 0.26154\n",
            "The time for epoch 105 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.78301, F1-score: 0.199235 \t Precision: 0.15572\t Recall: 0.27650\tNDCG: 0.26161\n",
            "The time for epoch 106 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.75830, F1-score: 0.199070 \t Precision: 0.15553\t Recall: 0.27647\tNDCG: 0.26217\n",
            "The time for epoch 107 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.74643, F1-score: 0.198766 \t Precision: 0.15539\t Recall: 0.27574\tNDCG: 0.26168\n",
            "The time for epoch 108 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.71926, F1-score: 0.198632 \t Precision: 0.15539\t Recall: 0.27522\tNDCG: 0.26212\n",
            "The time for epoch 109 is: train time = 00: 00: 10, test time = 00: 00: 01\n",
            "Loss = 17.37531, F1-score: 0.198481 \t Precision: 0.15518\t Recall: 0.27530\tNDCG: 0.26062\n",
            "The time for epoch 110 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.38103, F1-score: 0.198001 \t Precision: 0.15492\t Recall: 0.27426\tNDCG: 0.26057\n",
            "The time for epoch 111 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.69448, F1-score: 0.199171 \t Precision: 0.15584\t Recall: 0.27589\tNDCG: 0.26228\n",
            "The time for epoch 112 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.13231, F1-score: 0.199425 \t Precision: 0.15585\t Recall: 0.27681\tNDCG: 0.26218\n",
            "The time for epoch 113 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.45011, F1-score: 0.198538 \t Precision: 0.15517\t Recall: 0.27554\tNDCG: 0.26103\n",
            "The time for epoch 114 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.95297, F1-score: 0.197300 \t Precision: 0.15433\t Recall: 0.27344\tNDCG: 0.25929\n",
            "The time for epoch 115 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.16309, F1-score: 0.198152 \t Precision: 0.15509\t Recall: 0.27432\tNDCG: 0.26088\n",
            "The time for epoch 116 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.35722, F1-score: 0.198380 \t Precision: 0.15499\t Recall: 0.27551\tNDCG: 0.26100\n",
            "The time for epoch 117 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.11061, F1-score: 0.198104 \t Precision: 0.15489\t Recall: 0.27476\tNDCG: 0.26065\n",
            "The time for epoch 118 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.29982, F1-score: 0.197833 \t Precision: 0.15468\t Recall: 0.27437\tNDCG: 0.26038\n",
            "The time for epoch 119 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.12624, F1-score: 0.197941 \t Precision: 0.15492\t Recall: 0.27406\tNDCG: 0.26011\n",
            "The time for epoch 120 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.08451, F1-score: 0.197726 \t Precision: 0.15477\t Recall: 0.27370\tNDCG: 0.26036\n",
            "The time for epoch 121 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.28683, F1-score: 0.197355 \t Precision: 0.15439\t Recall: 0.27345\tNDCG: 0.25979\n",
            "The time for epoch 122 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.63221, F1-score: 0.197894 \t Precision: 0.15469\t Recall: 0.27458\tNDCG: 0.26015\n",
            "The time for epoch 123 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.28677, F1-score: 0.197510 \t Precision: 0.15464\t Recall: 0.27326\tNDCG: 0.26067\n",
            "The time for epoch 124 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.04777, F1-score: 0.197809 \t Precision: 0.15466\t Recall: 0.27436\tNDCG: 0.26101\n",
            "The time for epoch 125 is: train time = 00: 00: 10, test time = 00: 00: 01\n",
            "Loss = 17.22611, F1-score: 0.197531 \t Precision: 0.15443\t Recall: 0.27402\tNDCG: 0.26002\n",
            "The time for epoch 126 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.31800, F1-score: 0.197129 \t Precision: 0.15418\t Recall: 0.27323\tNDCG: 0.25889\n",
            "The time for epoch 127 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.32316, F1-score: 0.197461 \t Precision: 0.15440\t Recall: 0.27383\tNDCG: 0.25983\n",
            "The time for epoch 128 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.55445, F1-score: 0.197801 \t Precision: 0.15469\t Recall: 0.27422\tNDCG: 0.26047\n",
            "The time for epoch 129 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 16.91724, F1-score: 0.198161 \t Precision: 0.15502\t Recall: 0.27456\tNDCG: 0.26103\n",
            "##########################################\n",
            "Early stop is triggered at 129 epochs.\n",
            "Results:\n",
            "best epoch = 79, best recall = 0.2777892283166292, best ndcg = 0.26392490396180135\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "!python main.py --config_file ml-1m_config.ini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaULaOBO07aI",
        "outputId": "b4bacf74-c195-4696-e2e3-c6df469e7082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reproduced recall off by -0.32%\n",
            "reproduced NDCG off by -0.11%\n",
            "\n",
            "difference in epochs needed when reproducing: -7 epochs or -5.15%\n"
          ]
        }
      ],
      "source": [
        "recall_paper = 0.278671208895094\n",
        "ndcg_paper = 0.26421063460327485\n",
        "\n",
        "recall_reprod = 0.2777892283166292\n",
        "ndcg_reprod = 0.26392490396180135\n",
        "\n",
        "print_eval(recall_reprod, ndcg_reprod, recall_paper, ndcg_paper, 129, 136)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reproducing Dataset results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "Computing \\Omega for the item-item graph... \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\OneDrive - TU Wien\\Studium\\Master_1. Semester\\Experiment Design for Data Science\\ExpDesign_WS22\\UltraGCN\\main_custom_parameters.py:95: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  beta_uD = (np.sqrt(users_D + 1) / users_D).reshape(-1, 1)\n"
          ]
        }
      ],
      "source": [
        "import main_custom_parameters as main\n",
        "\n",
        "main.run('amazon_config.ini', n=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxRKrxBq0ty1",
        "outputId": "ba4f2b9c-46ab-407e-b409-777c030b1589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Computing \\Omega for the item-item graph... \n",
            "i-i constraint matrix 0 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./ml-1m_ii_neighbor_mat ok\n",
            "store object in path = ./ml-1m_ii_constraint_mat ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'gpu': '0', 'device': device(type='cuda', index=0), 'lr': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0.0001, 'lambda': 0.001, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The time for epoch 0 is: train time = 00: 00: 12, test time = 00: 00: 03\n",
            "Loss = 19.91279, F1-score: 0.091681 \t Precision: 0.07648\t Recall: 0.11443\tNDCG: 0.11596\n",
            "The time for epoch 5 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 18.20638, F1-score: 0.091183 \t Precision: 0.07611\t Recall: 0.11370\tNDCG: 0.11528\n",
            "The time for epoch 10 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.27180, F1-score: 0.091290 \t Precision: 0.07566\t Recall: 0.11505\tNDCG: 0.11492\n",
            "The time for epoch 15 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.36341, F1-score: 0.129567 \t Precision: 0.10807\t Recall: 0.16174\tNDCG: 0.17017\n",
            "The time for epoch 20 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.40980, F1-score: 0.157493 \t Precision: 0.12776\t Recall: 0.20527\tNDCG: 0.20656\n",
            "The time for epoch 25 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 15.94931, F1-score: 0.172548 \t Precision: 0.13822\t Recall: 0.22957\tNDCG: 0.22600\n",
            "The time for epoch 30 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.08956, F1-score: 0.180317 \t Precision: 0.14316\t Recall: 0.24353\tNDCG: 0.23581\n",
            "The time for epoch 35 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.71270, F1-score: 0.186643 \t Precision: 0.14766\t Recall: 0.25360\tNDCG: 0.24537\n",
            "The time for epoch 40 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.71788, F1-score: 0.190880 \t Precision: 0.15045\t Recall: 0.26103\tNDCG: 0.25027\n",
            "The time for epoch 45 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.25968, F1-score: 0.193948 \t Precision: 0.15245\t Recall: 0.26649\tNDCG: 0.25476\n",
            "The time for epoch 50 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.46021, F1-score: 0.195854 \t Precision: 0.15364\t Recall: 0.27004\tNDCG: 0.25733\n",
            "The time for epoch 51 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.63280, F1-score: 0.196292 \t Precision: 0.15430\t Recall: 0.26968\tNDCG: 0.25750\n",
            "The time for epoch 52 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.13210, F1-score: 0.195734 \t Precision: 0.15352\t Recall: 0.26997\tNDCG: 0.25851\n",
            "The time for epoch 53 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.51927, F1-score: 0.196934 \t Precision: 0.15442\t Recall: 0.27176\tNDCG: 0.25941\n",
            "The time for epoch 54 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.26227, F1-score: 0.197346 \t Precision: 0.15480\t Recall: 0.27214\tNDCG: 0.25925\n",
            "The time for epoch 55 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.91007, F1-score: 0.198102 \t Precision: 0.15536\t Recall: 0.27330\tNDCG: 0.25907\n",
            "The time for epoch 56 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.31599, F1-score: 0.198551 \t Precision: 0.15549\t Recall: 0.27460\tNDCG: 0.26147\n",
            "The time for epoch 57 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.99549, F1-score: 0.198045 \t Precision: 0.15520\t Recall: 0.27357\tNDCG: 0.26098\n",
            "The time for epoch 58 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.24116, F1-score: 0.198808 \t Precision: 0.15577\t Recall: 0.27470\tNDCG: 0.26144\n",
            "The time for epoch 59 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.90167, F1-score: 0.198243 \t Precision: 0.15531\t Recall: 0.27397\tNDCG: 0.26043\n",
            "The time for epoch 60 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.68484, F1-score: 0.197994 \t Precision: 0.15521\t Recall: 0.27335\tNDCG: 0.26006\n",
            "The time for epoch 61 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.42635, F1-score: 0.198508 \t Precision: 0.15538\t Recall: 0.27477\tNDCG: 0.26016\n",
            "The time for epoch 62 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 16.87586, F1-score: 0.198482 \t Precision: 0.15541\t Recall: 0.27460\tNDCG: 0.26152\n",
            "The time for epoch 63 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.30175, F1-score: 0.199576 \t Precision: 0.15631\t Recall: 0.27596\tNDCG: 0.26252\n",
            "The time for epoch 64 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.01346, F1-score: 0.199258 \t Precision: 0.15608\t Recall: 0.27547\tNDCG: 0.26162\n",
            "The time for epoch 65 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.24036, F1-score: 0.199909 \t Precision: 0.15650\t Recall: 0.27664\tNDCG: 0.26345\n",
            "The time for epoch 66 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.88608, F1-score: 0.200522 \t Precision: 0.15717\t Recall: 0.27691\tNDCG: 0.26330\n",
            "The time for epoch 67 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.64177, F1-score: 0.200345 \t Precision: 0.15706\t Recall: 0.27657\tNDCG: 0.26273\n",
            "The time for epoch 68 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.25554, F1-score: 0.199704 \t Precision: 0.15633\t Recall: 0.27640\tNDCG: 0.26260\n",
            "The time for epoch 69 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.89302, F1-score: 0.199344 \t Precision: 0.15595\t Recall: 0.27619\tNDCG: 0.26208\n",
            "The time for epoch 70 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.88643, F1-score: 0.199997 \t Precision: 0.15652\t Recall: 0.27692\tNDCG: 0.26258\n",
            "The time for epoch 71 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.33965, F1-score: 0.199309 \t Precision: 0.15593\t Recall: 0.27613\tNDCG: 0.26210\n",
            "The time for epoch 72 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.19024, F1-score: 0.200470 \t Precision: 0.15692\t Recall: 0.27746\tNDCG: 0.26330\n",
            "The time for epoch 73 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.43772, F1-score: 0.199825 \t Precision: 0.15653\t Recall: 0.27621\tNDCG: 0.26311\n",
            "The time for epoch 74 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.39361, F1-score: 0.199676 \t Precision: 0.15600\t Recall: 0.27731\tNDCG: 0.26268\n",
            "The time for epoch 75 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.08416, F1-score: 0.199940 \t Precision: 0.15627\t Recall: 0.27749\tNDCG: 0.26380\n",
            "The time for epoch 76 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.93247, F1-score: 0.198850 \t Precision: 0.15558\t Recall: 0.27546\tNDCG: 0.26227\n",
            "The time for epoch 77 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.32383, F1-score: 0.200194 \t Precision: 0.15663\t Recall: 0.27734\tNDCG: 0.26282\n",
            "The time for epoch 78 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.85132, F1-score: 0.199939 \t Precision: 0.15634\t Recall: 0.27727\tNDCG: 0.26308\n",
            "The time for epoch 79 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.23942, F1-score: 0.199794 \t Precision: 0.15599\t Recall: 0.27779\tNDCG: 0.26392\n",
            "The time for epoch 80 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.41440, F1-score: 0.199836 \t Precision: 0.15612\t Recall: 0.27756\tNDCG: 0.26276\n",
            "The time for epoch 81 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.57565, F1-score: 0.199386 \t Precision: 0.15604\t Recall: 0.27609\tNDCG: 0.26250\n",
            "The time for epoch 82 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.72587, F1-score: 0.199825 \t Precision: 0.15616\t Recall: 0.27739\tNDCG: 0.26301\n",
            "The time for epoch 83 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.07525, F1-score: 0.199140 \t Precision: 0.15565\t Recall: 0.27634\tNDCG: 0.26143\n",
            "The time for epoch 84 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.54578, F1-score: 0.200285 \t Precision: 0.15660\t Recall: 0.27777\tNDCG: 0.26334\n",
            "The time for epoch 85 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.89867, F1-score: 0.199284 \t Precision: 0.15587\t Recall: 0.27622\tNDCG: 0.26174\n",
            "The time for epoch 86 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.38805, F1-score: 0.200570 \t Precision: 0.15695\t Recall: 0.27777\tNDCG: 0.26360\n",
            "The time for epoch 87 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.88093, F1-score: 0.199005 \t Precision: 0.15566\t Recall: 0.27580\tNDCG: 0.26287\n",
            "The time for epoch 88 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.91226, F1-score: 0.199392 \t Precision: 0.15600\t Recall: 0.27622\tNDCG: 0.26114\n",
            "The time for epoch 89 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.18582, F1-score: 0.199435 \t Precision: 0.15601\t Recall: 0.27635\tNDCG: 0.26297\n",
            "The time for epoch 90 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.27471, F1-score: 0.199320 \t Precision: 0.15590\t Recall: 0.27625\tNDCG: 0.26281\n",
            "The time for epoch 91 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.58468, F1-score: 0.199261 \t Precision: 0.15560\t Recall: 0.27697\tNDCG: 0.26200\n",
            "The time for epoch 92 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.18991, F1-score: 0.199370 \t Precision: 0.15601\t Recall: 0.27610\tNDCG: 0.26218\n",
            "The time for epoch 93 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.61106, F1-score: 0.199120 \t Precision: 0.15573\t Recall: 0.27603\tNDCG: 0.26248\n",
            "The time for epoch 94 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.95034, F1-score: 0.199775 \t Precision: 0.15606\t Recall: 0.27751\tNDCG: 0.26338\n",
            "The time for epoch 95 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.89729, F1-score: 0.200048 \t Precision: 0.15634\t Recall: 0.27770\tNDCG: 0.26443\n",
            "The time for epoch 96 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.14818, F1-score: 0.199671 \t Precision: 0.15624\t Recall: 0.27656\tNDCG: 0.26281\n",
            "The time for epoch 97 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.68124, F1-score: 0.198959 \t Precision: 0.15550\t Recall: 0.27614\tNDCG: 0.26161\n",
            "The time for epoch 98 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.29868, F1-score: 0.199153 \t Precision: 0.15565\t Recall: 0.27639\tNDCG: 0.26193\n",
            "The time for epoch 99 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.21339, F1-score: 0.199464 \t Precision: 0.15585\t Recall: 0.27699\tNDCG: 0.26225\n",
            "The time for epoch 100 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.55200, F1-score: 0.199024 \t Precision: 0.15572\t Recall: 0.27569\tNDCG: 0.26196\n",
            "The time for epoch 101 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.78485, F1-score: 0.199040 \t Precision: 0.15576\t Recall: 0.27562\tNDCG: 0.26147\n",
            "The time for epoch 102 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.93698, F1-score: 0.198659 \t Precision: 0.15547\t Recall: 0.27507\tNDCG: 0.26108\n",
            "The time for epoch 103 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.26036, F1-score: 0.198038 \t Precision: 0.15497\t Recall: 0.27427\tNDCG: 0.26016\n",
            "The time for epoch 104 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.59708, F1-score: 0.198702 \t Precision: 0.15529\t Recall: 0.27581\tNDCG: 0.26154\n",
            "The time for epoch 105 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.78301, F1-score: 0.199235 \t Precision: 0.15572\t Recall: 0.27650\tNDCG: 0.26161\n",
            "The time for epoch 106 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.75830, F1-score: 0.199070 \t Precision: 0.15553\t Recall: 0.27647\tNDCG: 0.26217\n",
            "The time for epoch 107 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.74643, F1-score: 0.198766 \t Precision: 0.15539\t Recall: 0.27574\tNDCG: 0.26168\n",
            "The time for epoch 108 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.71926, F1-score: 0.198632 \t Precision: 0.15539\t Recall: 0.27522\tNDCG: 0.26212\n",
            "The time for epoch 109 is: train time = 00: 00: 10, test time = 00: 00: 01\n",
            "Loss = 17.37531, F1-score: 0.198481 \t Precision: 0.15518\t Recall: 0.27530\tNDCG: 0.26062\n",
            "The time for epoch 110 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.38103, F1-score: 0.198001 \t Precision: 0.15492\t Recall: 0.27426\tNDCG: 0.26057\n",
            "The time for epoch 111 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.69448, F1-score: 0.199171 \t Precision: 0.15584\t Recall: 0.27589\tNDCG: 0.26228\n",
            "The time for epoch 112 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.13231, F1-score: 0.199425 \t Precision: 0.15585\t Recall: 0.27681\tNDCG: 0.26218\n",
            "The time for epoch 113 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 17.45011, F1-score: 0.198538 \t Precision: 0.15517\t Recall: 0.27554\tNDCG: 0.26103\n",
            "The time for epoch 114 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.95297, F1-score: 0.197300 \t Precision: 0.15433\t Recall: 0.27344\tNDCG: 0.25929\n",
            "The time for epoch 115 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.16309, F1-score: 0.198152 \t Precision: 0.15509\t Recall: 0.27432\tNDCG: 0.26088\n",
            "The time for epoch 116 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.35722, F1-score: 0.198380 \t Precision: 0.15499\t Recall: 0.27551\tNDCG: 0.26100\n",
            "The time for epoch 117 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.11061, F1-score: 0.198104 \t Precision: 0.15489\t Recall: 0.27476\tNDCG: 0.26065\n",
            "The time for epoch 118 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.29982, F1-score: 0.197833 \t Precision: 0.15468\t Recall: 0.27437\tNDCG: 0.26038\n",
            "The time for epoch 119 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.12624, F1-score: 0.197941 \t Precision: 0.15492\t Recall: 0.27406\tNDCG: 0.26011\n",
            "The time for epoch 120 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.08451, F1-score: 0.197726 \t Precision: 0.15477\t Recall: 0.27370\tNDCG: 0.26036\n",
            "The time for epoch 121 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.28683, F1-score: 0.197355 \t Precision: 0.15439\t Recall: 0.27345\tNDCG: 0.25979\n",
            "The time for epoch 122 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 16.63221, F1-score: 0.197894 \t Precision: 0.15469\t Recall: 0.27458\tNDCG: 0.26015\n",
            "The time for epoch 123 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.28677, F1-score: 0.197510 \t Precision: 0.15464\t Recall: 0.27326\tNDCG: 0.26067\n",
            "The time for epoch 124 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.04777, F1-score: 0.197809 \t Precision: 0.15466\t Recall: 0.27436\tNDCG: 0.26101\n",
            "The time for epoch 125 is: train time = 00: 00: 10, test time = 00: 00: 01\n",
            "Loss = 17.22611, F1-score: 0.197531 \t Precision: 0.15443\t Recall: 0.27402\tNDCG: 0.26002\n",
            "The time for epoch 126 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.31800, F1-score: 0.197129 \t Precision: 0.15418\t Recall: 0.27323\tNDCG: 0.25889\n",
            "The time for epoch 127 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.32316, F1-score: 0.197461 \t Precision: 0.15440\t Recall: 0.27383\tNDCG: 0.25983\n",
            "The time for epoch 128 is: train time = 00: 00: 10, test time = 00: 00: 00\n",
            "Loss = 17.55445, F1-score: 0.197801 \t Precision: 0.15469\t Recall: 0.27422\tNDCG: 0.26047\n",
            "The time for epoch 129 is: train time = 00: 00: 09, test time = 00: 00: 00\n",
            "Loss = 16.91724, F1-score: 0.198161 \t Precision: 0.15502\t Recall: 0.27456\tNDCG: 0.26103\n",
            "##########################################\n",
            "Early stop is triggered at 129 epochs.\n",
            "Results:\n",
            "best epoch = 79, best recall = 0.2777892283166292, best ndcg = 0.26392490396180135\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "#TODO: use data subset\n",
        "!python main.py --config_file amazon_config.ini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaULaOBO07aI",
        "outputId": "b4bacf74-c195-4696-e2e3-c6df469e7082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reproduced recall off by -0.32%\n",
            "reproduced NDCG off by -0.11%\n",
            "\n",
            "difference in epochs needed when reproducing: -7 epochs or -5.15%\n"
          ]
        }
      ],
      "source": [
        "recall_paper = \n",
        "ndcg_paper = \n",
        "\n",
        "recall_reproduced = 0.2777892283166292\n",
        "ndcg_reproduced = 0.26392490396180135\n",
        "\n",
        "print_eval(recall_reprod, ndcg_reprod, recall_paper, ndcg_paper, 129, 136)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1XSpKHJNEe4"
      },
      "source": [
        "## Ablation study\n",
        "disable different parameters by overwriting:\n",
        "1. lambda = 0, gamma = 0\n",
        "1. lambda = 0\n",
        "1. gamma = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja-DTm_BgM2c",
        "outputId": "c57d8c6d-ee3b-4e62-97a9-98bbb1f3345a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import main_custom_parameters as main\n",
        "\n",
        "main.run('amazon_config.ini', report_progress=False, n=10_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGQZ_Kxzip8d"
      },
      "outputs": [],
      "source": [
        "recall_paper = 0.06809152719270753\n",
        "ndcg_paper = 0.05558807004339008\n",
        "\n",
        "recall_reproduced = 0.2777892283166292\n",
        "ndcg_reproduced = 0.26392490396180135\n",
        "\n",
        "recall_repro_off_by = (recall_reproduced - recall_paper) / recall_paper\n",
        "ndcg_repro_off_by = (ndcg_reproduced - ndcg_paper) / ndcg_paper\n",
        "\n",
        "print(f\"reproduced recall off by {round(recall_repro_off_by * 100, 2)}%\")\n",
        "print(f\"reproduced NDCG off by {round(ndcg_repro_off_by * 100, 2)}%\")\n",
        "print()\n",
        "print(f\"difference in epochs needed when reproducing: {129 - 136} epochs or {round((129 - 136) / 136 * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G82RyTggNXyn",
        "outputId": "42aa0497-600b-4119-f70c-9889ac074c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Computing \\Omega for the item-item graph... \n",
            "i-i constraint matrix 0 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./ml-1m_ii_neighbor_mat ok\n",
            "store object in path = ./ml-1m_ii_constraint_mat ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'gpu': '0', 'device': device(type='cuda', index=0), 'lr': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0, 'lambda': 0, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##########################################\n",
            "Early stop is triggered at 95 epochs.\n",
            "Results:\n",
            "best epoch = 25, best recall = 0.26376766521827877, best ndcg = 0.24618628698587772\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'gamma': 0, \n",
        "    'lambda': 0\n",
        "}\n",
        "main.run('amazon_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS-9lGmzPcEZ",
        "outputId": "4cd9c6dc-dfca-4572-f82f-fb59930b58cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "\n",
            "load path = ./ml-1m_ii_constraint_mat object\n",
            "load path = ./ml-1m_ii_neighbor_mat object\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'gpu': '0', 'device': device(type='cuda', index=0), 'lr': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0.0001, 'lambda': 0, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n",
            "##########################################\n",
            "Early stop is triggered at 131 epochs.\n",
            "Results:\n",
            "best epoch = 81, best recall = 0.2779974602196757, best ndcg = 0.26317962348703133\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'lambda': 0\n",
        "}\n",
        "main.run('amazon_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrG68foiPfUo",
        "outputId": "c9666a55-523b-4134-a3b9-7279a7fd78bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "\n",
            "load path = ./ml-1m_ii_constraint_mat object\n",
            "load path = ./ml-1m_ii_neighbor_mat object\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'gpu': '0', 'device': device(type='cuda', index=0), 'lr': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0, 'lambda': 0.001, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n",
            "##########################################\n",
            "Early stop is triggered at 96 epochs.\n",
            "Results:\n",
            "best epoch = 30, best recall = 0.26274388673973464, best ndcg = 0.2427880831841379\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'gamma': 0 \n",
        "}\n",
        "main.run('amazon_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "AQsRg2DLUFNN",
        "outputId": "54602b05-55aa-4bc1-fbb3-d3599b8510d1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 4\n",
        "model_names = ['UltraGCN\\n(\\u03BB=0,\\u03B3=0)', 'UltraGCN\\n(\\u03B3=0)', 'UltraGCN\\n(\\u03BB=0)', 'UltraGCN']\n",
        "recall_results = [0.26376766521827877, 0.2779974602196757, 0.26274388673973464, recall_paper]\n",
        "ndcg_results = [0.24618628698587772, 0.26317962348703133, 0.2427880831841379, ndcg_paper]\n",
        "\n",
        "plt_, ax = plt.subplots(1, 2, figsize=(12,6))\n",
        "ax[0].bar(range(n), recall_results, width=0.9, tick_label=model_names)\n",
        "ax[0].set_xticks(range(n))\n",
        "ax[0].set_yticks(np.arange(0.02, 0.08, 0.01))\n",
        "ax[0].set_xlabel('model')\n",
        "ax[0].set_ylabel('Recall@20')\n",
        "\n",
        "ax[1].bar(range(n), ndcg_results, width=0.9, color='orange', tick_label=model_names)\n",
        "ax[1].set_xticks(range(n))\n",
        "ax[1].set_yticks(np.arange(0.02, 0.07, 0.01))\n",
        "ax[1].set_xlabel('model')\n",
        "ax[1].set_ylabel('NDCG@20')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwnGr_65MiRx"
      },
      "source": [
        "## Parameter Influence\n",
        "\n",
        "Appying different parameter settings. \n",
        "\n",
        "for K = [5, 10, 20, 50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z34o-vMTMzLr",
        "outputId": "ba4fb652-d4fe-4fdc-c742-5701667ef0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing \\Omega for the item-item graph... \n",
            "i-i constraint matrix 0 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./ml-1m_ii_neighbor_mat_5 ok\n",
            "store object in path = ./ml-1m_ii_constraint_mat_5 ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 5, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'train_file_path': './data/ml-1m/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0.0001, 'lambda': 0.001, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/ml-1m/test.txt', 'device': device(type='cuda', index=0), 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##########################################\n",
            "Early stop is triggered at 137 epochs.\n",
            "Results:\n",
            "best epoch = 87, best recall = 0.2785188430018465, best ndcg = 0.26397130073045444\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "import main_custom_parameters as main\n",
        "\n",
        "custom_params = {\n",
        "    'ii_neighbor_num': 5 \n",
        "}\n",
        "main.run('ml-1m_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_YkC6G4M91d",
        "outputId": "d0e5555c-c1d9-42fd-a797-2da98238f1e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "Computing \\Omega for the item-item graph... \n",
            "i-i constraint matrix 0 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./ml-1m_ii_neighbor_mat_10 ok\n",
            "store object in path = ./ml-1m_ii_constraint_mat_10 ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 10, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'train_file_path': './data/ml-1m/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0.0001, 'lambda': 0.001, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/ml-1m/test.txt', 'device': device(type='cuda', index=0), 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n",
            "##########################################\n",
            "Early stop is triggered at 131 epochs.\n",
            "Results:\n",
            "best epoch = 81, best recall = 0.27767623319600715, best ndcg = 0.2644003166363614\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'ii_neighbor_num': 10 \n",
        "}\n",
        "main.run('ml-1m_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psqs6YpQNF-6",
        "outputId": "f41267b6-ec02-46ba-d2c4-f80d6136cde0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "Computing \\Omega for the item-item graph... \n",
            "i-i constraint matrix 0 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./ml-1m_ii_neighbor_mat_20 ok\n",
            "store object in path = ./ml-1m_ii_constraint_mat_20 ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 20, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'train_file_path': './data/ml-1m/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0.0001, 'lambda': 0.001, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/ml-1m/test.txt', 'device': device(type='cuda', index=0), 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n",
            "##########################################\n",
            "Early stop is triggered at 134 epochs.\n",
            "Results:\n",
            "best epoch = 84, best recall = 0.27783663535255726, best ndcg = 0.2633583423080468\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'ii_neighbor_num': 20 \n",
        "}\n",
        "main.run('ml-1m_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NdwNgkSNH-5",
        "outputId": "76bf7863-457e-4591-c4ee-6a574dd2657f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################### UltraGCN ######################\n",
            "1. Loading Configuration...\n",
            "Computing \\Omega for the item-item graph... \n",
            "i-i constraint matrix 0 ok\n",
            "Computation \\Omega OK!\n",
            "store object in path = ./ml-1m_ii_neighbor_mat_50 ok\n",
            "store object in path = ./ml-1m_ii_constraint_mat_50 ok\n",
            "Load Configuration OK, show them below\n",
            "Configuration:\n",
            "{'embedding_dim': 128, 'ii_neighbor_num': 50, 'model_save_path': './ultragcn_ml-1m.pt', 'max_epoch': 2000, 'enable_tensorboard': True, 'initial_weight': 0.001, 'dataset': 'ml-1m', 'train_file_path': './data/ml-1m/train.txt', 'gpu': '0', 'learning_rate': 0.001, 'batch_size': 1024, 'early_stop_epoch': 50, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 200, 'negative_weight': 200.0, 'gamma': 0.0001, 'lambda': 0.001, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 20, 'test_file_path': './data/ml-1m/test.txt', 'device': device(type='cuda', index=0), 'user_num': 6022, 'item_num': 3043}\n",
            "Total training batches = 778\n",
            "##########################################\n",
            "Early stop is triggered at 123 epochs.\n",
            "Results:\n",
            "best epoch = 73, best recall = 0.27705164310561525, best ndcg = 0.2633251503451496\n",
            "The best model is saved at ./ultragcn_ml-1m.pt\n",
            "Training end!\n",
            "END\n"
          ]
        }
      ],
      "source": [
        "custom_params = {\n",
        "    'ii_neighbor_num': 50 \n",
        "}\n",
        "main.run('ml-1m_config.ini', custom_params, report_progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "97VMi9kqNJIv",
        "outputId": "04d88954-9b38-4b3a-aefa-150f90810578"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAFzCAYAAAAkFp78AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5RddX338fd3LrkBkVvKKgkhEeNTAoYQRipYy0XQaJWLrVwsq2Ljk1WVR6zYmoptfays5QNan9LyVECUemURFUxdIiiEahtQBghIAkhCVZJSrsptcpnL9/njnEnOTH4zmSHnzElm3q+1Zs3ev/3b53znnGR/zm/vffaOzESSpMFaml2AJGn3ZEBIkooMCElSkQEhSSoyICRJRQaEJKmordkF1MuBBx6Yc+bMaXYZkrRHufvuu5/OzBmlZeMmIObMmUNnZ2ezy5CkPUpE/HKoZe5ikiQVGRCSpCIDQpJUNG6OQUjSULq7u9mwYQObN29udilNM2XKFGbNmkV7e/uI1zEgJI17GzZsYJ999mHOnDlERLPLGXOZyTPPPMOGDRuYO3fuiNdzF5OkcW/z5s0ccMABEzIcACKCAw44YNQjKANC0oQwUcOh38v5+w0ISSpYtf5pXv/p21i1/um6PF5raysLFy7kyCOP5O1vfzu/+c1v6vK4/ebMmcPTT1dq3XvvvevymAaEJA2yav3TLLm2k42/2cSSazvrEhJTp05l9erVPPDAA+y///5cccUVdai0sQwISarRHw6bunsB2NTdW7eQ6HfcccexceNGANavX8/ixYs55phjeMMb3sBDDz0EwBNPPMGZZ57JUUcdxVFHHcWqVasAOOOMMzjmmGM44ogjuOqqq+pWU4lnMUmaUP73v65h7X89X1z23KZufv7EC/QNuhPzpu5ezvvCT3j1Qfvwiqk7niY6/+Dp/O3bjxjR8/f29nLrrbeyZMkSAJYuXcrnP/955s2bx09+8hPe//73c9ttt/HBD36QE044gRtuuIHe3l5efPFFAL74xS+y//77s2nTJl772tfyh3/4hxxwwAGjeAVGzoCQpKpHn3pph3Do15eV5UfP3vdlPfamTZtYuHAhGzdu5PDDD+fUU0/lxRdfZNWqVbzzne/c1m/Lli0A3HbbbXz5y18GKscvXvGKVwBw+eWXc8MNNwDw2GOP8cgjjxgQklQPw33SH7x7qdbU9lauOb+D4w878GU9b/8xiK6uLt785jdzxRVXcP7557PvvvuyevXqET3G7bffzg9/+EPuuOMOpk2bxoknntjQL/95DEKSqo4/7ECuOb+Dqe2tA9p3NRxqTZs2jcsvv5zPfvazTJs2jblz57J8+XKg8oW2++67D4A3vvGN/PM//zNQ2S313HPP8dxzz7Hffvsxbdo0HnroIe68885drmc4BoQk1RgcEvUMh35HH300CxYs4Bvf+AZf+9rXuOaaazjqqKM44ogj+M53vgPAP/zDP7By5Upe85rXcMwxx7B27VoWL15MT08Phx9+OMuWLeN1r3td3WoqicwhdrjtYTo6OtL7QUgqefDBBzn88MNHtc6q9U/zF8vv57J3LqhrODRT6XWIiLszs6PU32MQklRw/GEH8h/LTm52GU3lLiZJUpEBIUkqMiAkSUUGhCSpyICQJBUZEJJU8sRKuHFO5XcdRAQXXXTRtvnPfOYzfOITnwDgE5/4BDNnzmThwoXMmzePd7zjHaxdu3Zb3+7ubpYtW8a8efNYtGgRxx13HDfddBMAL774Iu973/s47LDDWLRoEccccwxXX311XWo2ICRpsCdWwu1vg65fVn7XISQmT57Mt7/97W33bBjsz//8z1m9ejWPPPIIZ599NieffDJPPfUUAH/913/N448/zgMPPMA999zDjTfeyAsvvADAe9/7Xvbbbz8eeeQR7rnnHr7//e/z7LPP7nK90OCAiIjFEfFwRKyLiGWF5X8WET+LiNUR8e8RMb9m2V9V13s4It7cyDolaZv+cOjtqsz3dtUlJNra2li6dCmf+9zndtr37LPP5k1vehNf//rX6erq4uqrr+Yf//EfmTx5MgAHHXQQZ511FuvXr+enP/0pn/rUp2hpqWzOZ8yYwUc/+tFdqnVbzXV5lIKIaAWuAE4FNgB3RcSKzFxb0+3rmfn5av/TgL8HFleD4hzgCOBg4IcR8erM3PEKWpI0Gnd/CH49xMXxtv4afvMA0DewvbcLbj0F9j0SJu2343r7LYRj/u9On/oDH/gACxYs4C//8i932nfRokU89NBDrFu3jtmzZzN9+vQd+qxZs4ajjjpqWzjUWyNHEMcC6zLz0czcClwHnF7bITNrL8q+F9B/3Y/Tgesyc0tm/iewrvp4ktQ4zz/MDuGwTV91+cs3ffp0/uRP/oTLL798p31fzmWQLrnkEhYuXMjBBx/8csrbQSMvtTETeKxmfgPwu4M7RcQHgA8Dk4D+77XPBGovU7ih2iZJu2a4T/qDdy/Vap0GJ34XDjppl57+Qx/6EIsWLeI973nPsP3uvfdeOjo6eNWrXsWvfvUrnn/++R1GEfPnz+e+++6jr6+PlpYWLr74Yi6++OLxc0/qzLwiMw8DPgp8fDTrRsTSiOiMiM7+gzmS9LIddFIlBFqnDWyvUzgA7L///px11llcc801Q/b51re+xS233MK5557LtGnTWLJkCRdeeCFbt24F4KmnnmL58uW86lWvoqOjg49//OP09lb2wG/evPlljT5KGhkQG4FDauZnVduGch1wxmjWzcyrMrMjMztmzJixi+VKEjuGRB3Dod9FF120w9lMn/vc57ad5vrVr36V2267jf7t2qc+9SlmzJjB/PnzOfLII3nb2962bTTxhS98gWeeeWZbWJx66qlceumldamzYZf7jog24OfAG6ls3O8C3pWZa2r6zMvMR6rTbwf+NjM7IuII4OtUjjscDNwKzBvuILWX+5Y0lJdzuW+eWAl3vAeO+1Jdw6GZdpvLfWdmT0RcANwMtAJfzMw1EfFJoDMzVwAXRMQpQDfwa+Dd1XXXRMT1wFqgB/iAZzBJGlMHnQRn/KLZVTRVQ+8HkZnfA743qO1vaqYvHGbdS4BLGledJGk4TT9ILUnaPRkQkiaE8XJ75Zfr5fz9BoSkcW/KlCk888wzEzYkMpNnnnmGKVOmjGo970ktadybNWsWGzZsYCJ/X2rKlCnMmjVrVOsYEJLGvfb2dubOndvsMvY47mKSJBUZEJKkIgNCklRkQEiSigwISVKRASFJKjIgJElFBoQkqciAkCQVGRCSpCIDQpJUZEBIkooMCElSkQEhSSoyICRJRQaEJKnIgJAkFRkQkqQiA0KSVGRASJKKDAhJUpEBIUkqMiAkSUUGhCSpyICQJBUZEJKkIgNCklRkQEiSigwISVKRASFJKjIgJElFBoQkqciAkCQVNTQgImJxRDwcEesiYllh+YcjYm1E3B8Rt0bEoTXL/k9EPFD9ObuRdUqSdtSwgIiIVuAK4C3AfODciJg/qNu9QEdmLgC+CVxaXfcPgEXAQuB3gY9ExPRG1SpJ2lEjRxDHAusy89HM3ApcB5xe2yEzV2ZmV3X2TmBWdXo+8KPM7MnMl4D7gcUNrFWSNEgjA2Im8FjN/IZq21CWADdVp+8DFkfEtIg4EDgJOKQhVUqSitqaXQBARJwHdAAnAGTmLRHxWmAV8BRwB9BbWG8psBRg9uzZY1avJE0EjRxBbGTgp/5Z1bYBIuIU4GLgtMzc0t+emZdk5sLMPBUI4OeD183MqzKzIzM7ZsyYUfc/QJImskYGxF3AvIiYGxGTgHOAFbUdIuJo4Eoq4fBkTXtrRBxQnV4ALABuaWCtkqRBGraLKTN7IuIC4GagFfhiZq6JiE8CnZm5ArgM2BtYHhEAv8rM04B24MfVtueB8zKzp1G1SpJ21NBjEJn5PeB7g9r+pmb6lCHW20zlTCZJUpP4TWpJUpEBIUkqMiAkSUUGhCSpyICQJBUZEJKkIgNCklRkQEiSigwISVKRASFJKjIgJElFBoQkqciAkCQVGRCSpCIDQpJUZEBIkooMCElSkQEhSSoyICRJRQaEJKnIgJAkFRkQkqQiA0KSVGRASJKKDAhJUpEBIUkqMiAkSUUGhCSpyICQJBUZEJKkIgNCklRkQEiSigwISVKRASFJKjIgJElFBoQkqciAkCQVGRCSpKKGBkRELI6IhyNiXUQsKyz/cESsjYj7I+LWiDi0ZtmlEbEmIh6MiMsjIhpZqyRpoIYFRES0AlcAbwHmA+dGxPxB3e4FOjJzAfBN4NLquscDrwcWAEcCrwVOaFStkqQdNXIEcSywLjMfzcytwHXA6bUdMnNlZnZVZ+8EZvUvAqYAk4DJQDvwRANrlSQN0siAmAk8VjO/odo2lCXATQCZeQewEni8+nNzZj7YoDolSQW7xUHqiDgP6AAuq86/CjicyohiJnByRLyhsN7SiOiMiM6nnnpqLEuWpHGvkQGxETikZn5WtW2AiDgFuBg4LTO3VJvPBO7MzBcz80UqI4vjBq+bmVdlZkdmdsyYMaPuf4AkTWSNDIi7gHkRMTciJgHnACtqO0TE0cCVVMLhyZpFvwJOiIi2iGincoDaXUySNIYaFhCZ2QNcANxMZeN+fWauiYhPRsRp1W6XAXsDyyNidUT0B8g3gfXAz4D7gPsy818bVeuq9U/z+k/fxqr1TzfqKSRpjxOZ2ewa6qKjoyM7OztHvd6q9U+z5NpONnX3MrW9lWvO7+D4ww5sQIWStPuJiLszs6O0bLc4SN0sq9Y/zZ9eexebunsB2NTdy59eexf//ogjCUlqa3YBzdI/ctjc3TegfXN3H+dd8xPaWoJ9prQxbVIbUye1Mm1SK1PbK78HtE1qZVp72/bpSdv7bG+rmW5vpa11QueyxtCq9U/zF8vv57J3LnBkrFGbsAHxF8vv3zZyKJnS3srbjzqYrq29bNraS9fWHl7a2svTL26la2tXpa27l66tvWzt6RvycUomtbYMDJhqyEwdFC61y6dOamNae2s5dGrWn9S2e4ePG6yxU7v7dMm1ne4+1ahN2GMQtf95BhvtsYie3j42dfcHSeVnU3fPtumurT01QVNdXm3r6t4eQAPX7+WlLT1sGWX4tLVEYQRTCphq24DRURvTJrdW+7UNGBFNndTKpNYWduWSWB7vGTulf9++5ioZ7hjEhA0I2DP+E/X2JZu6CwHSHyrdhdAphVL39uWbakJoNFpbgmntQwfMXpPbtu1Gq10+dVIrG37dxedvf5StvdsDb1JbC8sW/w7zD55OXyZ9fVR+Z5LZP011vjLd2zf88srj1Ewn1WW1faGvL+ndyfLtj5EDH6tv4GP3Dq6jb+jnrv07c8Dj1zxWYfngv3e4v3FrTy+bussfLAKYud8U9ps2mcltLUxqa2FyWwuT21qZ3N5S09Y6oH1Sa0t1eX97Tb/2mscY9HiTWltoafE6m420q6NyA2IYE/lTbV9fsrlne+C8tMNIp2dAmBRHQt09vLSl2tY9sP+e8k+rJaAlgpYIYts02+ZbW/qXRU1fKvMtlfnWAevWTLewbd3WnSyvraOlZnkMaouA1v62bcu3r7v87sd4actwu09bOP6wA9nS08uW7j629PSxtaevMt9Tmd/S3cvW3j66e3f9TWxvjYHh0d5aEziVMNkeVDsLpep0TfvOQ27XRr67s3psvwyInXC/eP1lJpu7++ja2sNbL/8xTzy/Zci+B+49iX9616Lqhri8Qezf+LUOscGs3bBGxKDHKgdAa0uMyw1HPXef9vblgPDon95cDZYtPb3Vtu3Bsr1fTeh097G1d3sgDXy8vm1htbW3r9pne1j19u36NmpSWwuTW3ceLDuEVX+YFUNpYFgNXq/2OXZ192xJvfaAGBBqqnpusDQye8Lu05Hq6a0NjsGhVBs65VHQkKHU3VsOuUFhtbmnPqPh0Y6CBu+2q92lt+HZLr606hfFEd5o32cDQk03njZYe4qJvPu0njKTnr4cuCtuJ2G1wy67YdcbPPIqhFxP36hCaua+U/mPZSePqO9wATFhT3PV2Dr+sAO55vwON1hjqP81d/fprokI2luD9taWyt1pmiAz6e7NbeFxx/pn+Mjy+4pnOU5tb+Wydy6oy/M6gtCY8niPVB+7xTGIiGijcjOfM4GDq80bge8A12Rm94graSADQtJE0+izmEbytduvAAuBTwBvrf78b+Ao4KujqkSSVDf9uxFn7ju1IbtsR3IM4pjMfPWgtg3AnRHx87pWI0kaleMPO3DEB6RHayQjiGcj4p0Rsa1vRLRExNnArxtSlSSp6UYSEOcAfwQ8ERE/r44a/ht4R3WZJGkc2ukupsz8BXA2QEQcUG17prFlSZKabUTXho6I6RFxWGY+UxsOEVGfk20lSbudnQZERJwFPAR8KyLWRMRraxZf26jCJEnNNZIRxMeonMm0EHgP8JWIOLO6bPxd6UySBIzsNNfWzHwcIDN/GhEnAd+NiEOA8fE1bEnSDkYygnghIg7rn6mGxYnA6cARDapLktRkIxlBvI9Bu5Iy84WIWAyc1ZCqJElNN5LTXO+rna+e6vrr6jWYvtaowiRJzTWiy31HxH7A3wGvAR4H9ouIjcD/ysyXGlifJKlJdhoQEbEv8D3gY5l5QU37ScCnI+J6YE1mPtu4MiVJY20kB6n/GvhMZq6MiK9ExCMRcQdwFTCTyvGJjzeySEnS2BtJQPx+Zn6rOr0FODczj6Ny+Y1ngH8HTmpQfZKkJhlJQEyJiP6zmBYB/QetHwAWZeaO97yTJO3xRnKQ+qfAG4EfAv8PuKW6i+k44MrqpTfWNK5ESVIzjCQgLgGuj4g/yMwvRMSNwCuBv6cyAlkBvLuBNUqSmmAk34N4NCI+AKyIiFuAO4Fett9+9KLMfLixZUqSxtqIvgeRmT+JiOOo7Go6qtp8J/CpzOxpVHGSpOYZUUAAVA9G/6D6I0ka50byRbkXqFy1NRh49dYAMjOnN6g2SVITjeQYxD5jUYgkafcykhHE/sMt9xIbkjQ+jeQYxN1s38U0WFI55VWSNM7s9JvUmTk3M19Z/T34Z9hwiIjFEfFwRKyLiGWF5R+OiLURcX9E3BoRh1bbT4qI1TU/myPijJf/Z0qSRmvEZzHBtst+zwOm9Ldl5o+G6NsKXAGcCmwA7oqIFZm5tqbbvUBHZnZFxPuAS4GzM3MlsLD6OPsD64BbRlOrJGnXjDggIuK9wIXALGA18DrgDuDkIVY5FliXmY9W17+Oym1KtwVENQj63QmcV3icPwJuysyukdYqSdp1I7lYX78LgdcCv8zMk4Cjgd8M038m8FjN/IZq21CWADcV2s8BvjGKOiVJdTCaXUybM3NzRBARkzPzoYj4H/UoIiLOAzqAEwa1/zaVu9jdPMR6S4GlALNnz65HKZKkqtGMIDZU7y53I/CDiPgO8Mth+m8EDqmZn1VtGyAiTgEuBk7LzC2DFp8F3FC9//UOMvOqzOzIzI4ZM2aM4k+RJO3MaC61cWZ18hMRsRJ4BfD9YVa5C5gXEXOpBMM5wLtqO0TE0cCVwOLMfLLwGOcCfzXSGiVJ9TPiEUREvC4i9gHIzH8DbqdyHKKoehG/C6jsHnoQuD4z10TEJyPitGq3y4C9geXV01lX1DzfHCojkH8bzR8kSaqPyMyd9wIi4l4qd5DL6nwL0JmZixpY34h1dHRkZ2dns8uQpD1KRNydmR2lZaM5BhFZkybVq7uO6nsUkqQ9x2gC4tGI+GBEtFd/LgQebVRhkqTmGk1A/BlwPJUDzhuA36V6iqkkafwZzVlMT1I5E0mSNAGM5iymV1cvqPdAdX5BRHy8caVJkpppNLuYrqbynYRugMy8H0cUkjRujSYgpmXmTwe19dSzGEnS7mM0AfF0RBxG9b7UEfFHwOMNqUqS1HSj+R7DB4CrgN+JiI3AfwJ/3JCqJElNN5qzmB4FTomIvaiMPLqoHIMY7oJ9kqQ91E53MUXE9Ij4q4j4p4g4lUowvJvKXd7OanSBkqTmGMkI4ivAr6ncPe5/Urk0dwBnZubqBtYmSWqikQTEKzPzNQAR8QUqB6ZnZ+bmhlYmSWqqkZzFtO1mPZnZC2wwHCRp/BvJCOKoiHi+Oh3A1Op8AJmZ0xtWnSSpaXYaEJnZOhaFSJJ2L6P5opwkaQIxIDS2nlgJN86p/Ja0WzMgNHaeWAm3vw26fln5bUhIuzUDAvxUOxb6w6G3qzLf22VISLs57yldu+G6/W1w4nfhoJOaXVX9ZEL2Ql839G2t/uxseojl2Q29w0xnte/g6c3/Dc/eA/QNrK23C247FQ5+G7xiPrTvA+3TKz9tNdO17a3TIKIpL6U00UzsgBjqU+1QIZG5fYP5cjeWpelRbbxHsCEfPF25AG9jRCu0TKr+tBem2+G5tewQDtte017Y+K/wX9+tTO/0+VoGhsdQQTLcsv721sl1fSmk8WbiBsTgcOjX2wW3vhEmHVD5pFq7wc0G3/5iZxva2ra2vQa2Rzu0Tto+3TKpMh9DrD+a5xpyeXtlg70zQ73WUBkRnPhd+K0ToXczdD8PPS9Ufnc/D93V6Z6a6R36PAddj9Use5ERhWLLpEpwtE0fPkhq29uG6Neym54N/sRKuOM9cNyXxtfIWNs18D2OzAZ+uhxDHR0d2dnZOfIVbpxTOVg6lLa9Yc55Y7ShnVT5JD6ed52UQqI/HOq94co+6HlpFAFTOz1oWe+mkT1n67SdBMz0QWE0RL+2ver376D2NW/Ua63mqsN7HBF3Z2ZHcdmEDYiRfKr1P1N97YkbrL6emsB4GQHT/UI1nJ6v7u7bmRh+FFMKmFK/Z++FH79jbAJZzVGnD10GxFDG8lOtKibyLo/eLS8vYEojoF05rjTpgJrjLzWjlQEjlyGmG92naTWM9fPt4rpbfw2/eYDisb1RbsMMiOHsiZ9qNbFlVv69DhUw93yosgEZStvecOjZOz7m9pny9FB9dmXd3aLP7lLHKPo8fSf0bWFI0w6FM34x9PIawwXExD1I3e+gkyqhMFE/1WrPE1E5VtG2F0z97R2X73XI8LtPT1jhv/M93c52kR/3pbo8jV+Ug8p/ljN+4X8ajQ/9H3papw1sd4Q8fozRe2xASOPR4A2I4TD+jMF7bEBI41X/BmTaoYbDeNXg99hjENJ41r/7VONXA99jRxCSpCIDQpJUZEBIkooMCElSkQEhSSoyICRJRQ0NiIhYHBEPR8S6iFhWWP7hiFgbEfdHxK0RcWjNstkRcUtEPFjtM6eRtUqSBmpYQEREK3AF8BZgPnBuRMwf1O1eoCMzFwDfBC6tWfZl4LLMPBw4FniyUbVKknbUyBHEscC6zHw0M7cC1wGn13bIzJWZ2X+1qTuBWQDVIGnLzB9U+71Y00+SNAYaGRAzgcdq5jdU24ayBLipOv1q4DcR8e2IuDciLquOSCRJY2S3OEgdEecBHcBl1aY24A3AR4DXAq8Ezi+stzQiOiOi86mnnhqjaiVpYmhkQGwEDqmZn1VtGyAiTgEuBk7LzP47YGwAVld3T/UANwKLBq+bmVdlZkdmdsyYMaPuf4AkTWSNDIi7gHkRMTciJgHnACtqO0TE0cCVVMLhyUHr7hsR/Vv9k4G1DaxVkjRIwwKi+sn/AuBm4EHg+sxcExGfjIjTqt0uA/YGlkfE6ohYUV23l8rupVsj4mdUbs56daNqlSTtyHtSS9IENtw9qXeLg9SSpN2PASFJKjIgJElFBoQkqciAkCQVGRCSpCIDQpJUZEBIkooMCElSkQEhSSoyICRJRQaEJKnIgJAkFRkQkqQiA0KSVGRASJKKDAhJUpEBIUkqMiAkSUUGhCSpyICQJBUZEJKkIgNCklRkQEiSigwISVKRASFJKjIgJElFBoQkqciAkCQVGRCSpCIDQpJUZEBIkooMCElSkQEhSSoyICRJRQaEJKnIgJAkFRkQkqSihgZERCyOiIcjYl1ELCss/3BErI2I+yPi1og4tGZZb0Ssrv6saGSdkqQdtTXqgSOiFbgCOBXYANwVESsyc21Nt3uBjszsioj3AZcCZ1eXbcrMhY2qT5I0vEaOII4F1mXmo5m5FbgOOL22Q2auzMyu6uydwKwG1iNJGoVGBsRM4LGa+Q3VtqEsAW6qmZ8SEZ0RcWdEnNGIAiVJQ2vYLqbRiIjzgA7ghJrmQzNzY0S8ErgtIn6WmesHrbcUWAowe/bsMatXkiaCRo4gNgKH1MzPqrYNEBGnABcDp2Xmlv72zNxY/f0ocDtw9OB1M/OqzOzIzI4ZM2bUt3pJmuAaGRB3AfMiYm5ETALOAQacjRQRRwNXUgmHJ2va94uIydXpA4HXA7UHtyVJDdawXUyZ2RMRFwA3A63AFzNzTUR8EujMzBXAZcDewPKIAPhVZp4GHA5cGRF9VELs04POfpIkNVhkZrNrqIuOjo7s7OxsdhmStEeJiLszs6O0zG9SS5KKDAhJUpEBIUkqMiAkSUUGhCSpyICQJBUZEJKkIgNCklRkQEiSigwISVKRASFJKjIgJElFBoQkqciAkCQVGRCSpCIDQpJUZEBIkooMCElSkQEhSSoyICRJRQaEJKnIgJAkFRkQkqQiA0KSVGRASJKKDAhJUpEBIUkqMiAkSUUGhCSpyICQJBUZEJKkIgNCklRkQEiSigwISVKRASFJKjIgJElFBoQkqciAkCQVNTQgImJxRDwcEesiYllh+YcjYm1E3B8Rt0bEoYOWT4+IDRHxT42sU5K0o4YFRES0AlcAbwHmA+dGxPxB3e4FOjJzAfBN4NJBy/8O+FGjapQkDa2RI4hjgXWZ+WhmbgWuA06v7ZCZKzOzqzp7JzCrf1lEHAMcBNzSwBolSUNoZEDMBB6rmd9QbRvKEuAmgIhoAT4LfKRh1UmShtXW7AIAIuI8oAM4odr0fuB7mbkhIoZbbymwFGD27NmNLlOSJpRGBsRG4JCa+VnVtgEi4hTgYuCEzNxSbT4OeENEvB/YG5gUES9m5oAD3Zl5FXAVQEdHR9b/T5CkiauRAXEXMC8i5lIJhnOAd9V2iIijgSuBxZn5ZH97Zv5xTZ/zqRzI3uEsKElS4zTsGERm9gAXADcDD7eear4AAANtSURBVALXZ+aaiPhkRJxW7XYZlRHC8ohYHRErGlWPJGl0InN87Jnp6OjIzs7OZpchSXuUiLg7MztKy/wmtSSpyICQJBUZEJKkIgNCklRkQEiSigwISVKRASFJKjIgJElFBoQkqWjcfJM6Ip4CfrkLD3Eg8HSdytHwfK3Hlq/3+Lcr7/GhmTmjtGDcBMSuiojOob5urvrytR5bvt7jX6PeY3cxSZKKDAhJUpEBsd1VzS5gAvG1Hlu+3uNfQ95jj0FIkoocQUiSiiZ8QETELyLiZ9U72nnHoTqLiC9GxJMR8UBN2/4R8YOIeKT6e79m1jheRMQhEbEyItZGxJqIuLDa7us9zpS2W414nyd8QFSdlJkLPRWwIa4FFg9qWwbcmpnzgFur89p1PcBFmTkfeB3wgYiYj6/3eDV4u1X399mAUENl5o+AZwc1nw78S3X6X4AzxrSocSozH8/Me6rTL1C5F/xMfL0nirq/zwYEJHBLRNwdEUubXcwEcVBmPl6d/m/goGYWMx5FxBzgaOAn+HqPR6XtVt3f57ZdfYBx4Pcyc2NE/Bbwg4h4qPqpV2MgMzMiPJWujiJib+BbwIcy8/mI2LbM13vc2GG7VbuwXu/zhB9BZObG6u8ngRuAY5tb0YTwRET8NkD195NNrmfciIh2KuHwtcz8drXZ13ucGWK7Vff3eUIHRETsFRH79E8DbwIeGH4t1cEK4N3V6XcD32liLeNGVIYK1wAPZubf1yzy9R5Hhtlu1f19ntBflIuIV1JJX6jsbvt6Zl7SxJLGnYj4BnAilatNPgH8LXAjcD0wm8oVeM/KzMEHsjVKEfF7wI+BnwF91eaPUTkO4es9Tgy13YqIA6jz+zyhA0KSNLQJvYtJkjQ0A0KSVGRASJKKDAhJUpEBIUkqMiCkBoqIF2um3xoRP4+IQ5tZkzRSXmpDGgMR8UbgcuDNmfnLZtcjjYQBITVYRPw+cDXw1sxc3+x6pJHyi3JSA0VEN/ACcGJm3t/seqTR8BiE1FjdwCpgSbMLkUbLgJAaqw84Czg2Ij7W7GKk0fAYhNRgmdkVEX8A/DginsjMa5pdkzQSBoQ0BjLz2YhYDPwoIp7KzBXNrknaGQ9SS5KKPAYhSSoyICRJRQaEJKnIgJAkFRkQkqQiA0KSVGRASJKKDAhJUtH/B4AhbQZdon1VAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "n = 4\n",
        "k= [5, 10, 20, 50]\n",
        "recall_results = [0.2785188430018465, 0.27767623319600715, 0.27783663535255726, 0.27705164310561525]\n",
        "ndcg_results = [0.26397130073045444, 0.2644003166363614, 0.2633583423080468, 0.2633251503451496]\n",
        "\n",
        "plt_, ax = plt.subplots(1, 1, figsize=(6,6))\n",
        "ax.plot(k, recall_results, marker='D')\n",
        "ax.set_ylim(min(recall_results + ndcg_results)*0.9, max(recall_results + ndcg_results)*1.1)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xticks(k)\n",
        "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
        "ax.minorticks_off()\n",
        "ax.set_xlabel('K')\n",
        "ax.set_ylabel('Recall@20')\n",
        "ax.plot(k, ndcg_results, color = 'orange', marker='D')\n",
        "ax.legend(['Recall', 'NDCG'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtOKp7F_kyP7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "c9f5fc863bfeb52628e16391e02b82346ddba486f3a90a174bf61c42516759ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
